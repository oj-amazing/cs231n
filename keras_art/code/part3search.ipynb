{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import keras\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "#weights_path = '../model/vgg16_weights.h5'\n",
    "top_model_weights_path = '../model/bottleneck_fc_model.h5'\n",
    "#top_model_weights_path = '../model/fc_model.h5'\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "#full\n",
    "#train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "#validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "#nb_train_samples = 14313\n",
    "#nb_validation_samples = 1772\n",
    "#total_num_classes = 18\n",
    "\n",
    "#small\n",
    "train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "nb_train_samples = 1462\n",
    "nb_validation_samples = 167\n",
    "total_num_classes = 18\n",
    "\n",
    "#verysmall\n",
    "#train_data_dir = '../data/verysmall/train'\n",
    "#validation_data_dir = '../data/verysmall/val'\n",
    "#nb_train_samples = 144 #157\n",
    "#nb_validation_samples = 16 #18\n",
    "#total_num_classes = 2\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "#top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='sigmoid'))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "# model.add(top_model)\n",
    "\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_with_parameters(frozen_layers = 25, lr = 1e-4, momentum = 0.9, shear_range=0.2, zoom_range=0.2, horizontal_flip=True):\n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True;\n",
    "    \n",
    "    for layer in model.layers[:frozen_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    # fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_with_parameters(frozen_layers = 25, lr = 1e-4, momentum = 0.9, shear_range=0.2, zoom_range=0.2, horizontal_flip=True):\n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True;\n",
    "    \n",
    "    for layer in model.layers[:frozen_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    weight_path = os.path.join(weight_dir, \"best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path), verbose=1,monitor='val_acc', save_best_only=True)\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels),callbacks=[checkpointer])\n",
    "    \"\"\"\n",
    "    \n",
    "    pretrained_model = \"temp_name\"\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    weight_path = os.path.join(weight_dir, \"best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "    # fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples,\n",
    "        callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "frozen_layers_val = 25\n",
      "lr_val = 0.0001\n",
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Epoch 1/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.6208 - acc: 0.1681Epoch 00000: val_acc improved from -inf to 0.15688, saving model to ../model/temp_name/best_weightstemp_name.h5\n",
      "91/91 [==============================] - 38s - loss: 2.6238 - acc: 0.1662 - val_loss: 2.5787 - val_acc: 0.1569\n",
      "Epoch 2/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.6392 - acc: 0.1671Epoch 00001: val_acc did not improve\n",
      "91/91 [==============================] - 38s - loss: 2.6420 - acc: 0.1667 - val_loss: 2.5814 - val_acc: 0.1565\n",
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Epoch 1/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.6397 - acc: 0.1799Epoch 00000: val_acc improved from -inf to 0.15609, saving model to ../model/temp_name/best_weightstemp_name.h5\n",
      "91/91 [==============================] - 39s - loss: 2.6387 - acc: 0.1786 - val_loss: 2.5792 - val_acc: 0.1561\n",
      "Epoch 2/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.6381 - acc: 0.1565Epoch 00001: val_acc did not improve\n",
      "91/91 [==============================] - 38s - loss: 2.6385 - acc: 0.1575 - val_loss: 2.5796 - val_acc: 0.1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:65: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=91, epochs=2, callbacks=[<keras.ca..., validation_steps=167)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frozen_layers_arr = [25]\n",
    "lr_arr = [1e-4]\n",
    "momentum_arr = [0.9]\n",
    "shear_range_arr = [0.2]\n",
    "zoom_range_arr = [0.2]\n",
    "horizontal_flip_arr = [True]\n",
    "\n",
    "for frozen_layers_val in frozen_layers_arr:\n",
    "    for lr_val in lr_arr:\n",
    "        print(\"\\n\")\n",
    "        print(\"frozen_layers_val = \" + str(frozen_layers_val))\n",
    "        print(\"lr_val = \" + str(lr_val))\n",
    "        run_with_parameters(frozen_layers = frozen_layers_val, lr = lr_val)\n",
    "\n",
    "#run_with_parameters(frozen_layers = 25, lr = 1e-4, momentum = 0.9, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
