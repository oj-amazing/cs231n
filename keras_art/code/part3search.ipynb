{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "#top_model_weights_path = '../model/bottleneck_fc_model.h5'\n",
    "top_model_weights_path = '../model/bottleneck_fc_model_inceptionv3_500_val_acc_4791.h5'\n",
    "#top_model_weights_path = '../model/fc_model.h5'\n",
    "img_width, img_height = 500, 500\n",
    "\n",
    "#full\n",
    "#train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "#validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "#test_data_dir = '../data/Pandora18K_train_val_test_split/test'\n",
    "#nb_train_samples = 14313\n",
    "#nb_validation_samples = 1772\n",
    "#total_num_classes = 18\n",
    "\n",
    "#small\n",
    "train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "test_data_dir = '../data/Pandora18K_small_train_val_test_split/test'\n",
    "nb_train_samples = 1462\n",
    "nb_validation_samples = 167\n",
    "total_num_classes = 18\n",
    "\n",
    "#verysmall\n",
    "#train_data_dir = '../data/verysmall/train'\n",
    "#validation_data_dir = '../data/verysmall/val'\n",
    "#nb_train_samples = 144 #157\n",
    "#nb_validation_samples = 16 #18\n",
    "#total_num_classes = 2\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3))\n",
    "#base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.6))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(.6))\n",
    "top_model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Found 171 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "if False:\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-5, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "    _, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = nb_validation_samples // batch_size)\n",
    "    print(\"sanity_acc = \" + str(sanity_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_with_parameters(lr):\n",
    "    global best_acc\n",
    "    global best_weight_path\n",
    "    print(\"best val acc so far = \" + str(best_acc))\n",
    "    \n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    #    for layer in model.layers:\n",
    "    #        layer.trainable = True;\n",
    "    frozen_layers = 25\n",
    "    momentum = 0.9\n",
    "\n",
    "    for layer in model.layers[:311]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    pretrained_model = \"temp_name\"\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    param_names = \"frozen_layers_\" + str(frozen_layers) + \"_lr_\" + str(lr) + \"_momentum_\" + str(momentum)\n",
    "    weight_path = os.path.join(weight_dir, param_names + \"_best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=[checkpointer])\n",
    "    \n",
    "    model.load_weights(weight_path)\n",
    "    _, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = nb_validation_samples // batch_size)\n",
    "    print(\"sanity_acc = \"+ str(sanity_acc))\n",
    "    \n",
    "    if sanity_acc > best_acc:\n",
    "        model.load_weights(weight_path)\n",
    "        model.save_weights(best_weight_path, overwrite = True)\n",
    "        best_acc = sanity_acc\n",
    "    else:\n",
    "        os.remove(weight_path)\n",
    "    \n",
    "    print(\"best val acc so far = \" + str(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "lr = 2.18817300175e-05\n",
      "Epoch 1/1\n",
      "45/46 [============================>.] - ETA: 1s - loss: 5.6403 - acc: 0.1688Epoch 00000: val_acc improved from -inf to 0.76647, saving model to ../model/part_3_weights/lr_2.18817300175e-05_best_weightspart_3_weights.h5\n",
      "46/46 [==============================] - 83s - loss: 5.6024 - acc: 0.1730 - val_loss: 0.8567 - val_acc: 0.7665\n",
      "new_acc = 0.772455090534\n",
      "new_loss = 0.778284083583\n",
      "best val acc so far = 0.772455090534\n",
      "\n",
      "\n",
      "lr = 0.0106386074266\n",
      "Epoch 1/1\n",
      "45/46 [============================>.] - ETA: 1s - loss: 2.7781 - acc: 0.1489Epoch 00000: val_acc improved from -inf to 0.38922, saving model to ../model/part_3_weights/lr_0.0106386074266_best_weightspart_3_weights.h5\n",
      "46/46 [==============================] - 74s - loss: 2.7789 - acc: 0.1491 - val_loss: 1.8811 - val_acc: 0.3892\n",
      "new_acc = 0.413173653408\n",
      "new_loss = 1.8401535364\n",
      "best val acc so far = 0.772455090534\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = \"part_3_weights\"\n",
    "weight_dir = \"../model/%s\"%pretrained_model\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "\n",
    "best_weight_path = \"../model/best.h5\"\n",
    "best_acc = 0\n",
    "best_lr = 0\n",
    "best_frozen_layers = 0\n",
    "    \n",
    "for i in range(2):\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    lr = 10**np.random.uniform(low=-6, high=-3)\n",
    "    print(\"lr = \" + str(lr))\n",
    "\n",
    "    for layer in model.layers[:best_frozen_layers]: #312 layers total\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr),\n",
    "                  #momentum=0.9,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    param_names = \"lr_\" + str(lr)\n",
    "    weight_path = os.path.join(weight_dir, param_names + \"_best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=(nb_train_samples // batch_size)+1,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=(nb_validation_samples // batch_size)+1,\n",
    "        callbacks=[checkpointer])\n",
    "    \n",
    "    model.load_weights(weight_path)\n",
    "    new_loss, new_acc = model.evaluate_generator(generator = validation_generator, steps = (nb_validation_samples // batch_size)+1)\n",
    "    print(\"new_acc = \"+ str(new_acc))\n",
    "    print(\"new_loss = \"+ str(new_loss))\n",
    "    \n",
    "    if new_acc > best_acc:\n",
    "        model.load_weights(weight_path)\n",
    "        model.save_weights(best_weight_path, overwrite = True)\n",
    "        best_acc = new_acc\n",
    "        best_lr = lr\n",
    "    \n",
    "    print(\"best val acc so far = \" + str(best_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best val loss check = 0.820405879064\n",
      "best val acc check = 0.790419164532\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    model.load_weights(best_weight_path)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=best_lr),\n",
    "                  #momentum=0.9,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    sanity_loss, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = (nb_validation_samples // batch_size)+1)\n",
    "    print(\"best val loss check = \" + str(sanity_loss))\n",
    "    print(\"best val acc check = \" + str(sanity_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
