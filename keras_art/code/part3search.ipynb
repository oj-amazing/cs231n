{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "best_weight_path = \"../model/best.h5\"\n",
    "best_acc = 0\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "#top_model_weights_path = '../model/bottleneck_fc_model.h5'\n",
    "top_model_weights_path = '../model/bottleneck_fc_model_inceptionv3_500_val_acc_4791.h5'\n",
    "#top_model_weights_path = '../model/fc_model.h5'\n",
    "img_width, img_height = 500, 500\n",
    "\n",
    "#full\n",
    "#train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "#validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "#test_data_dir = '../data/Pandora18K_train_val_test_split/test'\n",
    "#nb_train_samples = 14313\n",
    "#nb_validation_samples = 1772\n",
    "#total_num_classes = 18\n",
    "\n",
    "#small\n",
    "train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "test_data_dir = '../data/Pandora18K_small_train_val_test_split/test'\n",
    "nb_train_samples = 1462\n",
    "nb_validation_samples = 167\n",
    "total_num_classes = 18\n",
    "\n",
    "#verysmall\n",
    "#train_data_dir = '../data/verysmall/train'\n",
    "#validation_data_dir = '../data/verysmall/val'\n",
    "#nb_train_samples = 144 #157\n",
    "#nb_validation_samples = 16 #18\n",
    "#total_num_classes = 2\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "[<keras.engine.topology.InputLayer object at 0x7f5dc4035910>, <keras.layers.convolutional.Conv2D object at 0x7f5dc4035790>, <keras.layers.normalization.BatchNormalization object at 0x7f5dc40356d0>, <keras.layers.core.Activation object at 0x7f5dc4035c50>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b8bc610>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b651790>, <keras.layers.core.Activation object at 0x7f5d8b6074d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b6afe10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b69b610>, <keras.layers.core.Activation object at 0x7f5d8b5e0590>, <keras.layers.pooling.MaxPooling2D object at 0x7f5d8b5e0690>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b59a0d0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b55bf90>, <keras.layers.core.Activation object at 0x7f5d8b504990>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b52a750>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b4c08d0>, <keras.layers.core.Activation object at 0x7f5d8b4ed610>, <keras.layers.pooling.MaxPooling2D object at 0x7f5d8b44ff50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b2f7f90>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b2df890>, <keras.layers.core.Activation object at 0x7f5d8b2a3f50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b43ca50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b25ecd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b43c350>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b270e50>, <keras.layers.core.Activation object at 0x7f5d8b34e890>, <keras.layers.core.Activation object at 0x7f5d8b238990>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d8b118f10>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b4aa650>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b3bca10>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b1ee710>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b172610>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b467bd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b362a10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b186890>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b132b90>, <keras.layers.core.Activation object at 0x7f5d8b42b0d0>, <keras.layers.core.Activation object at 0x7f5d8b30d750>, <keras.layers.core.Activation object at 0x7f5d8b1b35d0>, <keras.layers.core.Activation object at 0x7f5d8b0f2090>, <keras.layers.merge.Concatenate object at 0x7f5d8b084dd0>, <keras.layers.convolutional.Conv2D object at 0x7f5d8aed4d90>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8aec0390>, <keras.layers.core.Activation object at 0x7f5d8ae84510>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b016b50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8ae84610>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b02acd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8ae53b50>, <keras.layers.core.Activation object at 0x7f5d8afef810>, <keras.layers.core.Activation object at 0x7f5d8ae17690>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d8ad52a10>, <keras.layers.convolutional.Conv2D object at 0x7f5d8b084450>, <keras.layers.convolutional.Conv2D object at 0x7f5d8afa7590>, <keras.layers.convolutional.Conv2D object at 0x7f5d8ade8610>, <keras.layers.convolutional.Conv2D object at 0x7f5d8ad52310>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8b042850>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8af40710>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8adcd9d0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8ad2b390>, <keras.layers.core.Activation object at 0x7f5d8b070fd0>, <keras.layers.core.Activation object at 0x7f5d8af6c450>, <keras.layers.core.Activation object at 0x7f5d8ad96950>, <keras.layers.core.Activation object at 0x7f5d8ad3ed90>, <keras.layers.merge.Concatenate object at 0x7f5d8ace6b10>, <keras.layers.convolutional.Conv2D object at 0x7f5d8ab0acd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8ab1ee50>, <keras.layers.core.Activation object at 0x7f5d8aae5990>, <keras.layers.convolutional.Conv2D object at 0x7f5d8ac6aa10>, <keras.layers.convolutional.Conv2D object at 0x7f5d8aa9f710>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8ac0fa10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8aab5890>, <keras.layers.core.Activation object at 0x7f5d8ac3d750>, <keras.layers.core.Activation object at 0x7f5d8aa625d0>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d8a9b6b50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8ace6190>, <keras.layers.convolutional.Conv2D object at 0x7f5d8aba2f90>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a9c6f10>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a949cd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8aca6590>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8ab87890>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8aa30710>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a9100d0>, <keras.layers.core.Activation object at 0x7f5d8ac7b890>, <keras.layers.core.Activation object at 0x7f5d8ab4ef50>, <keras.layers.core.Activation object at 0x7f5d8a9f8dd0>, <keras.layers.core.Activation object at 0x7f5d8a8c5850>, <keras.layers.merge.Concatenate object at 0x7f5d8a9369d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a8595d0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a873750>, <keras.layers.core.Activation object at 0x7f5d8a820490>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a784dd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a7ef3d0>, <keras.layers.core.Activation object at 0x7f5d8a7b3550>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a936d10>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a7b3650>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a88bd90>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a704b90>, <keras.layers.core.Activation object at 0x7f5d8a8b4a10>, <keras.layers.core.Activation object at 0x7f5d8a6ca6d0>, <keras.layers.pooling.MaxPooling2D object at 0x7f5d8a69a5d0>, <keras.layers.merge.Concatenate object at 0x7f5d8a6f0910>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a453fd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a4ba8d0>, <keras.layers.core.Activation object at 0x7f5d8a401f90>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a43dd10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a3d1e90>, <keras.layers.core.Activation object at 0x7f5d8a3969d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a62f610>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a350750>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a614a50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a3678d0>, <keras.layers.core.Activation object at 0x7f5d8a5d9350>, <keras.layers.core.Activation object at 0x7f5d8a312610>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a540c90>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a2f8f50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a599390>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a2e3750>, <keras.layers.core.Activation object at 0x7f5d8a52a8d0>, <keras.layers.core.Activation object at 0x7f5d8a2a9e10>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d8a1f85d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a681450>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a519a50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a264b90>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a193750>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a648990>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a53ea50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a279d10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a1bdb10>, <keras.layers.core.Activation object at 0x7f5d8a6708d0>, <keras.layers.core.Activation object at 0x7f5d8a4ed790>, <keras.layers.core.Activation object at 0x7f5d8a1c4850>, <keras.layers.core.Activation object at 0x7f5d8a169550>, <keras.layers.merge.Concatenate object at 0x7f5d8a120f90>, <keras.layers.convolutional.Conv2D object at 0x7f5d89ee0cd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89f373d0>, <keras.layers.core.Activation object at 0x7f5d89e49910>, <keras.layers.convolutional.Conv2D object at 0x7f5d89e49290>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89e5da90>, <keras.layers.core.Activation object at 0x7f5d89e0b7d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a0b5e50>, <keras.layers.convolutional.Conv2D object at 0x7f5d89df2f50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a09e650>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89dd8910>, <keras.layers.core.Activation object at 0x7f5d8a0645d0>, <keras.layers.core.Activation object at 0x7f5d89d9ffd0>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a0646d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d89d5ad50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a035c10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89d6fed0>, <keras.layers.core.Activation object at 0x7f5d89ffc750>, <keras.layers.core.Activation object at 0x7f5d89d32a10>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d89c18f90>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a10b890>, <keras.layers.convolutional.Conv2D object at 0x7f5d89fb34d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d89cef790>, <keras.layers.convolutional.Conv2D object at 0x7f5d89c7f790>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8a138f50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89f4e650>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89c86910>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89bc8710>, <keras.layers.core.Activation object at 0x7f5d8a0fa4d0>, <keras.layers.core.Activation object at 0x7f5d89f7b390>, <keras.layers.core.Activation object at 0x7f5d89cb2650>, <keras.layers.core.Activation object at 0x7f5d89bf4150>, <keras.layers.merge.Concatenate object at 0x7f5d89bafc90>, <keras.layers.convolutional.Conv2D object at 0x7f5d899866d0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89954c10>, <keras.layers.core.Activation object at 0x7f5d8991d750>, <keras.layers.convolutional.Conv2D object at 0x7f5d898d24d0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d898ec650>, <keras.layers.core.Activation object at 0x7f5d89895390>, <keras.layers.convolutional.Conv2D object at 0x7f5d89b17c10>, <keras.layers.convolutional.Conv2D object at 0x7f5d8987ccd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89b2cd90>, <keras.layers.normalization.BatchNormalization object at 0x7f5d898523d0>, <keras.layers.core.Activation object at 0x7f5d89af08d0>, <keras.layers.core.Activation object at 0x7f5d897e8910>, <keras.layers.convolutional.Conv2D object at 0x7f5d89aa9650>, <keras.layers.convolutional.Conv2D object at 0x7f5d897e8290>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89a427d0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d897fea90>, <keras.layers.core.Activation object at 0x7f5d89a6c510>, <keras.layers.core.Activation object at 0x7f5d897aa7d0>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d896f7d50>, <keras.layers.convolutional.Conv2D object at 0x7f5d89b86e90>, <keras.layers.convolutional.Conv2D object at 0x7f5d899d0e50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8970ff50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8968bed0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89b46910>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89a3a650>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89775910>, <keras.layers.normalization.BatchNormalization object at 0x7f5d896532d0>, <keras.layers.core.Activation object at 0x7f5d89b07090>, <keras.layers.core.Activation object at 0x7f5d899865d0>, <keras.layers.core.Activation object at 0x7f5d8973dfd0>, <keras.layers.core.Activation object at 0x7f5d89669c90>, <keras.layers.merge.Concatenate object at 0x7f5d89669c50>, <keras.layers.convolutional.Conv2D object at 0x7f5d893c8610>, <keras.layers.normalization.BatchNormalization object at 0x7f5d893e0790>, <keras.layers.core.Activation object at 0x7f5d8938a4d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d89370e10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8935b610>, <keras.layers.core.Activation object at 0x7f5d89322590>, <keras.layers.convolutional.Conv2D object at 0x7f5d895a1790>, <keras.layers.convolutional.Conv2D object at 0x7f5d89322690>, <keras.layers.normalization.BatchNormalization object at 0x7f5d895b9910>, <keras.layers.normalization.BatchNormalization object at 0x7f5d892f0bd0>, <keras.layers.core.Activation object at 0x7f5d89566650>, <keras.layers.core.Activation object at 0x7f5d892ba710>, <keras.layers.convolutional.Conv2D object at 0x7f5d894cdf90>, <keras.layers.convolutional.Conv2D object at 0x7f5d89209610>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89533790>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8926ea50>, <keras.layers.core.Activation object at 0x7f5d894fbe50>, <keras.layers.core.Activation object at 0x7f5d89234350>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d89177a50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8a17d910>, <keras.layers.convolutional.Conv2D object at 0x7f5d894b6bd0>, <keras.layers.convolutional.Conv2D object at 0x7f5d8919ec90>, <keras.layers.convolutional.Conv2D object at 0x7f5d8911da50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d89623c50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8944cd50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d891f3390>, <keras.layers.normalization.BatchNormalization object at 0x7f5d890cae10>, <keras.layers.core.Activation object at 0x7f5d895fbbd0>, <keras.layers.core.Activation object at 0x7f5d8940f890>, <keras.layers.core.Activation object at 0x7f5d891088d0>, <keras.layers.core.Activation object at 0x7f5d890f2850>, <keras.layers.merge.Concatenate object at 0x7f5d890975d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d88fafd50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88f43ed0>, <keras.layers.core.Activation object at 0x7f5d88f09a10>, <keras.layers.convolutional.Conv2D object at 0x7f5d88ec0790>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88ed5910>, <keras.layers.core.Activation object at 0x7f5d88e84650>, <keras.layers.convolutional.Conv2D object at 0x7f5d89087c10>, <keras.layers.convolutional.Conv2D object at 0x7f5d88e6af90>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8905db10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88e52790>, <keras.layers.core.Activation object at 0x7f5d89006790>, <keras.layers.core.Activation object at 0x7f5d88e1ae50>, <keras.layers.convolutional.Conv2D object at 0x7f5d88fc4f50>, <keras.layers.convolutional.Conv2D object at 0x7f5d88dd3bd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d8902a910>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88de8d50>, <keras.layers.core.Activation object at 0x7f5d88ff2fd0>, <keras.layers.core.Activation object at 0x7f5d88daf890>, <keras.layers.pooling.MaxPooling2D object at 0x7f5d88d66610>, <keras.layers.merge.Concatenate object at 0x7f5d88d58ad0>, <keras.layers.convolutional.Conv2D object at 0x7f5d88b11b50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88b39710>, <keras.layers.core.Activation object at 0x7f5d88a91690>, <keras.layers.convolutional.Conv2D object at 0x7f5d88cfa690>, <keras.layers.convolutional.Conv2D object at 0x7f5d88a4ced0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88c92810>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88ab4810>, <keras.layers.core.Activation object at 0x7f5d88cbe550>, <keras.layers.core.Activation object at 0x7f5d88a7aed0>, <keras.layers.convolutional.Conv2D object at 0x7f5d88c22e90>, <keras.layers.convolutional.Conv2D object at 0x7f5d88bd4710>, <keras.layers.convolutional.Conv2D object at 0x7f5d88a33c50>, <keras.layers.convolutional.Conv2D object at 0x7f5d8894a690>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d7b84c710>, <keras.layers.convolutional.Conv2D object at 0x7f5d88d2bbd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88c0e690>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88ba5c50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d889c9dd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88962810>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b85d0d0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d88d2bc50>, <keras.layers.core.Activation object at 0x7f5d88bd4610>, <keras.layers.core.Activation object at 0x7f5d88b6a790>, <keras.layers.core.Activation object at 0x7f5d8898f910>, <keras.layers.core.Activation object at 0x7f5d8890e550>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b823710>, <keras.layers.core.Activation object at 0x7f5d88cd3ad0>, <keras.layers.merge.Concatenate object at 0x7f5d88b1e510>, <keras.layers.merge.Concatenate object at 0x7f5d7b875e90>, <keras.layers.core.Activation object at 0x7f5d7b7cc390>, <keras.layers.merge.Concatenate object at 0x7f5d7b787ed0>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b598350>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b55b750>, <keras.layers.core.Activation object at 0x7f5d7b50ad10>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b773a50>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b50ac50>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b773350>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b4c6b90>, <keras.layers.core.Activation object at 0x7f5d7b685890>, <keras.layers.core.Activation object at 0x7f5d7b48a6d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b6f3a10>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b62ef90>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b45a5d0>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b3c3a50>, <keras.layers.pooling.AveragePooling2D object at 0x7f5d7b342d50>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b7e0750>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b698a10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b616890>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b4bda10>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b3c3350>, <keras.layers.convolutional.Conv2D object at 0x7f5d7b317dd0>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b79eb50>, <keras.layers.core.Activation object at 0x7f5d7b648750>, <keras.layers.core.Activation object at 0x7f5d7b5daf50>, <keras.layers.core.Activation object at 0x7f5d7b406990>, <keras.layers.core.Activation object at 0x7f5d7b355890>, <keras.layers.normalization.BatchNormalization object at 0x7f5d7b317e50>, <keras.layers.core.Activation object at 0x7f5d7b7612d0>, <keras.layers.merge.Concatenate object at 0x7f5d7b598cd0>, <keras.layers.merge.Concatenate object at 0x7f5d7b342a10>, <keras.layers.core.Activation object at 0x7f5d7b2e88d0>, <keras.layers.merge.Concatenate object at 0x7f5d7b2d7a50>, <keras.models.Sequential object at 0x7f5d7b2fcad0>]\n",
      "312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:41: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3))\n",
    "#base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "#top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='sigmoid'))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='softmax'))\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "#top_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.6))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(.6))\n",
    "top_model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "# model.add(top_model)\n",
    "\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "print(model.layers)\n",
    "print(len(model.layers))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Found 171 images belonging to 18 classes.\n",
      "sanity_acc = 0.825\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "valid_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-5, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "_, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = nb_validation_samples // batch_size)\n",
    "print(\"sanity_acc = \" + str(sanity_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_with_parameters(lr):\n",
    "    global best_acc\n",
    "    global best_weight_path\n",
    "    print(\"best val acc so far = \" + str(best_acc))\n",
    "    \n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "#    for layer in model.layers:\n",
    "#        layer.trainable = True;\n",
    "    frozen_layers = 25\n",
    "    momentum = 0.9\n",
    "\n",
    "    for layer in model.layers[:312]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    pretrained_model = \"temp_name\"\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    param_names = \"frozen_layers_\" + str(frozen_layers) + \"_lr_\" + str(lr) + \"_momentum_\" + str(momentum)\n",
    "    weight_path = os.path.join(weight_dir, param_names + \"_best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=[checkpointer])\n",
    "    \n",
    "    model.load_weights(weight_path)\n",
    "    _, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = nb_validation_samples // batch_size)\n",
    "    print(\"sanity_acc = \"+ str(sanity_acc))\n",
    "    \n",
    "    if sanity_acc > best_acc:\n",
    "        print(\"updating best_acc by loading weights from \" + weight_path)\n",
    "        model.load_weights(weight_path)\n",
    "        model.save_weights(best_weight_path, overwrite = True)\n",
    "        best_acc = sanity_acc\n",
    "    \n",
    "    print(\"best val acc so far = \" + str(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best val acc so far = 0\n",
      "Epoch 1/1\n",
      "44/45 [============================>.] - ETA: 1s - loss: 5.4661 - acc: 0.1697"
     ]
    }
   ],
   "source": [
    "\n",
    "frozen_layers_arr = [25]\n",
    "lr_arr = [1e-4, 1e-5, 1e-2, 1e-6]\n",
    "momentum_arr = [0.9]\n",
    "shear_range_arr = [0.2]\n",
    "zoom_range_arr = [0.2]\n",
    "horizontal_flip_arr = [True]\n",
    "\n",
    "#0:lr,1:dense middle,2:dropout1, 3:dropout2\n",
    "#params=(10**np.random.uniform(low=-5, high=-1),np.random.randint(low = 50, high=800),np.random.uniform(low=0.3,high=0.8), np.random.uniform(low=0.3,high=0.8))\n",
    "\n",
    "for i in range(1):\n",
    "    frozen_layers_val = 25#np.random.randint(low = 25, high=25)\n",
    "    #lr_val = 10**np.random.uniform(low=-5, high=-1)\n",
    "    lr_val = 1e-8\n",
    "    #print(\"\\nlr_val = \" + str(lr_val))\n",
    "\n",
    "    run_with_parameters(lr = lr_val)\n",
    "            \n",
    "\n",
    "print(\"\\n\\n\\nbest val acc = \" + str(best_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sanity check that the saved best_weight_path contains weights that gets you an accuracy of best_acc\n",
    "#sanity_val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#sanity_val_generator = sanity_val_datagen.flow_from_directory(\n",
    "#    validation_data_dir,\n",
    "#    target_size=(img_width, img_height),\n",
    "#    batch_size=batch_size,\n",
    "#    class_mode='categorical')\n",
    "\n",
    "model.load_weights(best_weight_path)\n",
    "\n",
    "sanity_loss, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = (nb_validation_samples // batch_size)+1)\n",
    "print(\"best val loss check = \" + str(sanity_loss))\n",
    "print(\"best val acc check = \" + str(sanity_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
