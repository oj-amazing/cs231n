{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "# img_width, img_height = 224, 224\n",
    "img_width, img_height = 500, 500\n",
    "\n",
    "pretrained_model = \"inceptionv3_500\"\n",
    "\n",
    "\n",
    "top_model_weights_path = '../model/bottleneck_fc_model_%s.h5'%pretrained_model\n",
    "train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "test_data_dir = '../data/Pandora18K_small_train_val_test_split/test'\n",
    "nb_train_samples = 1462\n",
    "nb_validation_samples = 167\n",
    "nb_test_samples = 171\n",
    "# train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "# validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "# test_data_dir = '../data/Pandora18K_train_val_test_split/test'\n",
    "# nb_train_samples = 14313\n",
    "# nb_validation_samples = 1772\n",
    "# nb_test_samples = 1791\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "# build the VGG16 network\n",
    "# model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "train_data = np.load(open('../model/bottleneck_features_train_%s.npy'%pretrained_model))\n",
    "#full\n",
    "#train_labels = np.array([0]*684+[1]*598+[2]*655+[3]*657+[4]*808+[5]*675+[6]*715+[7]*946+[8]*995+[9]*1021+[10]*803+[11]*816+[12]*566+[13]*959+[14]*842+[15]*831+[16]*849+[17]*893)\n",
    "\n",
    "#small\n",
    "train_labels = np.array([0]*78+[1]*79+[2]*77+[3]*85+[4]*78+[5]*87+[6]*80+[7]*81+[8]*81+[9]*80+[10]*85+[11]*83+[12]*74+[13]*87+[14]*83+[15]*83+[16]*78+[17]*83)\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=18)\n",
    "\n",
    "validation_data = np.load(open('../model/bottleneck_features_validation_%s.npy'%pretrained_model))\n",
    "#full\n",
    "#validation_labels = np.array([0]*72+[1]*73+[2]*72+[3]*93+[4]*78+[5]*74+[6]*85+[7]*124+[8]*131+[9]*118+[10]*109+[11]*105+[12]*80+[13]*130+[14]*108+[15]*89+[16]*111+[17]*120)\n",
    "\n",
    "#small\n",
    "validation_labels = np.array([0]*8+[1]*10+[2]*11+[3]*5+[4]*11+[5]*6+[6]*8+[7]*8+[8]*9+[9]*12+[10]*7+[11]*10+[12]*14+[13]*5+[14]*11+[15]*11+[16]*12+[17]*9)\n",
    "validation_labels = to_categorical(validation_labels, num_classes=18)\n",
    "\n",
    "test_data = np.load(open('../model/bottleneck_features_test_%s.npy'%pretrained_model))\n",
    "#full\n",
    "#test_labels = np.array([0]*91+[1]*60+[2]*75+[3]*82+[4]*104+[5]*83+[6]*95+[7]*121+[8]*131+[9]*123+[10]*103+[11]*117+[12]*65+[13]*123+[14]*121+[15]*112+[16]*89+[17]*96)\n",
    "\n",
    "#small\n",
    "test_labels = np.array([0]*14+[1]*11+[2]*12+[3]*10+[4]*11+[5]*7+[6]*12+[7]*11+[8]*10+[9]*8+[10]*8+[11]*7+[12]*12+[13]*8+[14]*6+[15]*6+[16]*10+[17]*8)\n",
    "test_labels = to_categorical(test_labels, num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0064202836107099415, 743, 0.3284725026757753, 0.6173533813242693)\n",
      "Train on 1462 samples, validate on 167 samples\n",
      "Epoch 1/2\n",
      "1408/1462 [===========================>..] - ETA: 0s - loss: 14.5908 - acc: 0.0618Epoch 00000: val_acc improved from -inf to 0.04192, saving model to ../model/inceptionv3_500_small/temp_weights_inceptionv3_500_small.h5\n",
      "1462/1462 [==============================] - 20s - loss: 14.5921 - acc: 0.0629 - val_loss: 15.4425 - val_acc: 0.0419\n",
      "Epoch 2/2\n",
      "1408/1462 [===========================>..] - ETA: 0s - loss: 15.1451 - acc: 0.0604Epoch 00001: val_acc did not improve\n",
      "1462/1462 [==============================] - 12s - loss: 15.1810 - acc: 0.0581 - val_loss: 15.4425 - val_acc: 0.0419\n",
      "167/167 [==============================] - 0s     \n",
      "(0.0003408572226053028, 254, 0.5509599916847701, 0.7091901400786377)\n",
      "Train on 1462 samples, validate on 167 samples\n",
      "Epoch 1/2\n",
      "1408/1462 [===========================>..] - ETA: 0s - loss: 13.8895 - acc: 0.0668Epoch 00000: val_acc improved from -inf to 0.05389, saving model to ../model/inceptionv3_500_small/temp_weights_inceptionv3_500_small.h5\n",
      "1462/1462 [==============================] - 25s - loss: 13.9256 - acc: 0.0663 - val_loss: 15.1439 - val_acc: 0.0539\n",
      "Epoch 2/2\n",
      "1408/1462 [===========================>..] - ETA: 0s - loss: 14.0945 - acc: 0.0923Epoch 00001: val_acc improved from 0.05389 to 0.11377, saving model to ../model/inceptionv3_500_small/temp_weights_inceptionv3_500_small.h5\n",
      "1462/1462 [==============================] - 17s - loss: 14.0491 - acc: 0.0951 - val_loss: 12.9305 - val_acc: 0.1138\n",
      "167/167 [==============================] - 0s     \n",
      "{0.041916167664670656: (15.442486654498619, 0.041916167664670656, (0.0064202836107099415, 743, 0.3284725026757753, 0.6173533813242693)), 0.11377245508982035: (12.93046126679746, 0.11377245508982035, (0.0003408572226053028, 254, 0.5509599916847701, 0.7091901400786377))}\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "history = dict()\n",
    "for i in range(2):\n",
    "    best_acc = 0\n",
    "    \n",
    "    #0:lr,1:dense middle,2:dropout1, 3:dropout2\n",
    "    params=(10**np.random.uniform(low=-5, high=-1), \\\n",
    "            np.random.randint(low = 50, high=800), \\\n",
    "            np.random.uniform(low=0.3,high=0.8),\\\n",
    "            np.random.uniform(low=0.3,high=0.8))\n",
    "    print(params)\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dropout(params[2]))\n",
    "    model.add(Dense(params[1], activation='relu'))\n",
    "    model.add(Dropout(params[2]))\n",
    "    model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=params[0], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    weight_path = os.path.join(weight_dir, \"temp_weights_%s.h5\"%pretrained_model)\n",
    "    best_weight_path = os.path.join(weight_dir, \"best_weights_%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True)\n",
    "    stopper = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels),callbacks=[checkpointer,stopper])\n",
    "    model.load_weights(weight_path)\n",
    "    loss, acc = model.evaluate(validation_data, validation_labels, batch_size=32, verbose=1, sample_weight=None)\n",
    "    if acc>best_acc:\n",
    "        model.save_weights(best_weight_path)\n",
    "    history[acc] = (loss, acc, params)\n",
    "    \n",
    "print(history)\n",
    "pickle.dump(history, open(os.path.join(weight_dir,'history_%s.p'%pretrained_model),'w'))\n",
    "\n",
    "# model.save_weights(top_model_weights_path,overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.93046126679746, 0.11377245508982035]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(best_weight_path)\n",
    "model.evaluate(validation_data, validation_labels, batch_size=32, verbose=1, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.812165600514552, 0.15204678362573099]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_labels, batch_size=32, verbose=1, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "weight_dir = \"../model/%s\"%pretrained_model\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "weight_path = os.path.join(weight_dir, \"temp_weights_%s.h5\"%pretrained_model)\n",
    "history = pickle.load(open(os.path.join(weight_dir,'history_%s.p'%pretrained_model),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.54627539530295555: (1.9093075596452029,\n",
       "  0.54627539530295555,\n",
       "  (9.872134816612904e-05, 653, 0.40977067265920386, 0.7121187929915329))}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
