{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "#top_model_weights_path = '../model/bottleneck_fc_model.h5'\n",
    "top_model_weights_path = '../model/bottleneck_fc_model_inceptionv3_500_val_acc_4791.h5'\n",
    "#top_model_weights_path = '../model/fc_model.h5'\n",
    "img_width, img_height = 500, 500\n",
    "\n",
    "#full\n",
    "#train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "#validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "#test_data_dir = '../data/Pandora18K_train_val_test_split/test'\n",
    "#nb_train_samples = 14313\n",
    "#nb_validation_samples = 1772\n",
    "#nb_test_samples = 1791\n",
    "#total_num_classes = 18\n",
    "\n",
    "#small\n",
    "train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "test_data_dir = '../data/Pandora18K_small_train_val_test_split/test'\n",
    "nb_train_samples = 1462\n",
    "nb_validation_samples = 167\n",
    "nb_test_samples = 171\n",
    "total_num_classes = 18\n",
    "\n",
    "#verysmall\n",
    "#train_data_dir = '../data/verysmall/train'\n",
    "#validation_data_dir = '../data/verysmall/val'\n",
    "#nb_train_samples = 144 #157\n",
    "#nb_validation_samples = 16 #18\n",
    "#total_num_classes = 2\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3))\n",
    "#base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.6))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(.6))\n",
    "top_model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Found 171 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "if False:\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-5, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "    _, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = nb_validation_samples // batch_size)\n",
    "    print(\"sanity_acc = \" + str(sanity_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:36: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n",
      "/home/eraserwars/env_keras_tutorial/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:2250: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "lr = 2.64282138957e-06\n",
      "momentum = 0.882109323846\n",
      "number of frozen layers = 308\n",
      "Epoch 1/5\n",
      "45/46 [============================>.] - ETA: 1s - loss: 5.7357 - acc: 0.1576Epoch 00000: val_acc improved from -inf to 0.76647, saving model to ../model/part_3_weights/lr_2.64282138957e-06_best_weightspart_3_weights.h5\n",
      "46/46 [==============================] - 91s - loss: 5.7305 - acc: 0.1582 - val_loss: 0.8682 - val_acc: 0.7665\n",
      "Epoch 2/5\n",
      "45/46 [============================>.] - ETA: 1s - loss: 5.5963 - acc: 0.1472Epoch 00001: val_acc did not improve\n",
      "46/46 [==============================] - 75s - loss: 5.5952 - acc: 0.1460 - val_loss: 1.2150 - val_acc: 0.6347\n",
      "Epoch 3/5\n",
      "45/46 [============================>.] - ETA: 1s - loss: 5.4558 - acc: 0.1674Epoch 00002: val_acc did not improve\n",
      "46/46 [==============================] - 75s - loss: 5.4205 - acc: 0.1696 - val_loss: 1.7337 - val_acc: 0.5389\n",
      "new_acc = 0.766467066939\n",
      "new_loss = 0.86823830526\n",
      "best val acc so far = 0.766467066939\n",
      "\n",
      "\n",
      "lr = 0.000741818684843\n",
      "momentum = 0.833928268928\n",
      "number of frozen layers = 310\n",
      "Epoch 1/5\n",
      "45/46 [============================>.] - ETA: 1s - loss: 3.5657 - acc: 0.1949Epoch 00000: val_acc improved from -inf to 0.73054, saving model to ../model/part_3_weights/lr_0.000741818684843_best_weightspart_3_weights.h5\n",
      "46/46 [==============================] - 90s - loss: 3.5547 - acc: 0.1934 - val_loss: 1.0465 - val_acc: 0.7305\n",
      "Epoch 2/5\n",
      "45/46 [============================>.] - ETA: 1s - loss: 2.6261 - acc: 0.2124Epoch 00001: val_acc did not improve\n",
      "46/46 [==============================] - 75s - loss: 2.6227 - acc: 0.2126 - val_loss: 1.2877 - val_acc: 0.6347\n",
      "Epoch 3/5\n",
      "45/46 [============================>.] - ETA: 1s - loss: 2.4851 - acc: 0.1985Epoch 00002: val_acc did not improve\n",
      "46/46 [==============================] - 75s - loss: 2.4918 - acc: 0.1990 - val_loss: 1.4512 - val_acc: 0.5868\n",
      "new_acc = 0.730538923226\n",
      "new_loss = 0.982121587513\n",
      "best val acc so far = 0.766467066939\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = \"part_3_weights\"\n",
    "weight_dir = \"../model/%s\"%pretrained_model\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "\n",
    "best_weight_path = \"../model/best.h5\"\n",
    "best_acc = 0\n",
    "best_lr = 0\n",
    "best_momentum = 0\n",
    "best_frozen = 0\n",
    "num_parameter_sets = 2\n",
    "    \n",
    "for i in range(num_parameter_sets):\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    lr = 10**np.random.uniform(low=-7, high=-3)\n",
    "    momentum = np.random.uniform(low = 0.7, high = 0.9)\n",
    "    num_frozen = np.random.randint(300, high=312) #312 total\n",
    "    print(\"lr = \" + str(lr))\n",
    "    print(\"momentum = \" + str(momentum))\n",
    "    print(\"number of frozen layers = \" + str(num_frozen))\n",
    "    \n",
    "    # build the VGG16 network\n",
    "    base_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_height,img_width,3))\n",
    "\n",
    "    # build a classifier model to put on top of the convolutional model\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dropout(0.6))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(.6))\n",
    "    top_model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "    model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    for layer in model.layers[:num_frozen]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr),\n",
    "                  momentum=momentum,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    param_names = \"lr_\" + str(lr)\n",
    "    weight_path = os.path.join(weight_dir, param_names + \"_best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "    stopper = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=1, verbose=0, mode='auto')\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=(nb_train_samples // batch_size)+1,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=(nb_validation_samples // batch_size)+1,\n",
    "        callbacks=[checkpointer, stopper])\n",
    "    \n",
    "    model.load_weights(weight_path)\n",
    "    new_loss, new_acc = model.evaluate_generator(generator = validation_generator, steps = (nb_validation_samples // batch_size)+1)\n",
    "    print(\"new_acc = \"+ str(new_acc))\n",
    "    print(\"new_loss = \"+ str(new_loss))\n",
    "    \n",
    "    if new_acc > best_acc:\n",
    "        model.load_weights(weight_path)\n",
    "        model.save_weights(best_weight_path, overwrite = True)\n",
    "        best_acc = new_acc\n",
    "        best_lr = lr\n",
    "        best_momentum = momentum\n",
    "        best_frozen = num_frozen\n",
    "        \n",
    "    os.remove(weight_path)\n",
    "    \n",
    "    print(\"best val acc so far = \" + str(best_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best test loss = 0.995896580624\n",
      "best test acc = 0.66666666597\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(best_weight_path)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=best_lr),\n",
    "              momentum=best_momentum,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(generator = test_generator, steps = (nb_test_samples // batch_size)+1)\n",
    "print(\"best test loss = \" + str(test_loss))\n",
    "print(\"best test acc = \" + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
