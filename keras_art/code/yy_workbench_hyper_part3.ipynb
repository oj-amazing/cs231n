{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "# dimensions of our images.\n",
    "# img_width, img_height = 224, 224\n",
    "img_width, img_height = 500, 500\n",
    "\n",
    "pretrained_model = \"inceptionv3_500_part3\"\n",
    "best_weight_path_part2 = '../model/inceptionv3_500_0.5542/best_weights_inceptionv3_500.h5'\n",
    "incpetion_weight_path = '../model/inceptionv3_500_0.5857/finetune_weights_0.5857.h5'\n",
    "# best_weight_path = '../model/inceptionv3_500_0.5857/finetune_weights.h5'\n",
    "\n",
    "# top_model_weights_path = '../model/bottleneck_fc_model_%s.h5'%pretrained_model\n",
    "# train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "# validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "# test_data_dir = '../data/Pandora18K_small_train_val_test_split/test'\n",
    "# nb_train_samples = 1462\n",
    "# nb_validation_samples = 167\n",
    "# nb_test_samples = 171\n",
    "train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "test_data_dir = '../data/Pandora18K_train_val_test_split/test'\n",
    "nb_train_samples = 14313\n",
    "nb_validation_samples = 1772\n",
    "nb_test_samples = 1791\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "# build the VGG16 network\n",
    "# model = applications.VGG16(include_top=False, weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "train_data = np.load(open('../model/bottleneck_features_train_%s.npy'%pretrained_model))\n",
    "#full\n",
    "train_labels = np.array([0]*684+[1]*598+[2]*655+[3]*657+[4]*808+[5]*675+[6]*715+[7]*946+[8]*995+[9]*1021+[10]*803+[11]*816+[12]*566+[13]*959+[14]*842+[15]*831+[16]*849+[17]*893)\n",
    "\n",
    "#small\n",
    "#train_labels = np.array([0]*78+[1]*79+[2]*77+[3]*85+[4]*78+[5]*87+[6]*80+[7]*81+[8]*81+[9]*80+[10]*85+[11]*83+[12]*74+[13]*87+[14]*83+[15]*83+[16]*78+[17]*83)\n",
    "\n",
    "train_labels = to_categorical(train_labels, num_classes=18)\n",
    "\n",
    "validation_data = np.load(open('../model/bottleneck_features_validation_%s.npy'%pretrained_model))\n",
    "#full\n",
    "validation_labels = np.array([0]*72+[1]*73+[2]*72+[3]*93+[4]*78+[5]*74+[6]*85+[7]*124+[8]*131+[9]*118+[10]*109+[11]*105+[12]*80+[13]*130+[14]*108+[15]*89+[16]*111+[17]*120)\n",
    "\n",
    "#small\n",
    "#validation_labels = np.array([0]*8+[1]*10+[2]*11+[3]*5+[4]*11+[5]*6+[6]*8+[7]*8+[8]*9+[9]*12+[10]*7+[11]*10+[12]*14+[13]*5+[14]*11+[15]*11+[16]*12+[17]*9)\n",
    "validation_labels = to_categorical(validation_labels, num_classes=18)\n",
    "\n",
    "test_data = np.load(open('../model/bottleneck_features_test_%s.npy'%pretrained_model))\n",
    "#full\n",
    "test_labels = np.array([0]*91+[1]*60+[2]*75+[3]*82+[4]*104+[5]*83+[6]*95+[7]*121+[8]*131+[9]*123+[10]*103+[11]*117+[12]*65+[13]*123+[14]*121+[15]*112+[16]*89+[17]*96)\n",
    "\n",
    "#small\n",
    "#test_labels = np.array([0]*14+[1]*11+[2]*12+[3]*10+[4]*11+[5]*7+[6]*12+[7]*11+[8]*10+[9]*8+[10]*8+[11]*7+[12]*12+[13]*8+[14]*6+[15]*6+[16]*10+[17]*8)\n",
    "test_labels = to_categorical(test_labels, num_classes=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_inception_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.applications.inception_v3 import conv2d_bn\n",
    "from keras import layers\n",
    "from keras.layers import AveragePooling2D\n",
    "inputs = Input(shape=train_data.shape[1:], name=\"input_layer\")\n",
    "i = 1\n",
    "channel_axis = 3\n",
    "branch1x1 = conv2d_bn(inputs, 320, 1, 1)\n",
    "\n",
    "branch3x3 = conv2d_bn(inputs, 384, 1, 1)\n",
    "branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "branch3x3 = layers.concatenate(\n",
    "    [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n",
    "\n",
    "branch3x3dbl = conv2d_bn(inputs, 448, 1, 1)\n",
    "branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "branch3x3dbl = layers.concatenate(\n",
    "    [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
    "\n",
    "branch_pool = AveragePooling2D(\n",
    "    (3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "x = layers.concatenate(\n",
    "    [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "    axis=channel_axis,\n",
    "    name='mixed' + str(9 + i))\n",
    "\n",
    "base_model = Model(inputs, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model.layers[1 ].name='conv2d_90'\n",
    "base_model.layers[2 ].name='batch_normalization_90'\n",
    "base_model.layers[3 ].name='activation_90'\n",
    "base_model.layers[4 ].name='conv2d_87'\n",
    "base_model.layers[5 ].name='conv2d_91'\n",
    "base_model.layers[6 ].name='batch_normalization_87'\n",
    "base_model.layers[7 ].name='batch_normalization_91'\n",
    "base_model.layers[8 ].name='activation_87'\n",
    "base_model.layers[9 ].name='activation_91'\n",
    "base_model.layers[10].name='conv2d_88'\n",
    "base_model.layers[11].name='conv2d_89'\n",
    "base_model.layers[12].name='conv2d_92'\n",
    "base_model.layers[13].name='conv2d_93'\n",
    "base_model.layers[14].name='average_pooling2d_9'\n",
    "base_model.layers[15].name='conv2d_86'\n",
    "base_model.layers[16].name='batch_normalization_88'\n",
    "base_model.layers[17].name='batch_normalization_89'\n",
    "base_model.layers[18].name='batch_normalization_92'\n",
    "base_model.layers[19].name='batch_normalization_93'\n",
    "base_model.layers[20].name='conv2d_94'\n",
    "base_model.layers[21].name='batch_normalization_86'\n",
    "base_model.layers[22].name='activation_88'\n",
    "base_model.layers[23].name='activation_89'\n",
    "base_model.layers[24].name='activation_92'\n",
    "base_model.layers[25].name='activation_93'\n",
    "base_model.layers[26].name='batch_normalization_94'\n",
    "base_model.layers[27].name='activation_86'\n",
    "base_model.layers[28].name='mixed9_1'\n",
    "base_model.layers[29].name='concatenate_2'\n",
    "base_model.layers[30].name='activation_94'\n",
    "base_model.layers[31].name='mixed10'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Model(inputs, x, name='inception_v3')\n",
    "base_model.load_weights(incpetion_weight_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=(1.0e-07, 394, 0.7, 0.7)\n",
    "top_model=Sequential()\n",
    "top_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Dropout(params[2]))\n",
    "top_model.add(Dense(params[1], activation='relu'))\n",
    "top_model.add(Dropout(params[2]))\n",
    "top_model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "top_model.load_weights(best_weight_path_part2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_layer (InputLayer)         (None, 14, 14, 2048)  0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, 14, 14, 448)   917504      input_layer[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, 14, 14, 448)   1344        conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, 14, 14, 448)   0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, 14, 14, 384)   786432      input_layer[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, 14, 14, 384)   1548288     activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, 14, 14, 384)   1152        conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, 14, 14, 384)   1152        conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, 14, 14, 384)   0           batch_normalization_87[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, 14, 14, 384)   0           batch_normalization_91[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, 14, 14, 384)   442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, 14, 14, 384)   442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, 14, 14, 384)   442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, 14, 14, 384)   442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePool (None, 14, 14, 2048)  0           input_layer[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, 14, 14, 320)   655360      input_layer[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 14, 14, 384)   1152        conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 14, 14, 384)   1152        conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, 14, 14, 384)   1152        conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, 14, 14, 384)   1152        conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, 14, 14, 192)   393216      average_pooling2d_9[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, 14, 14, 320)   960         conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, 14, 14, 384)   0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, 14, 14, 384)   0           batch_normalization_89[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, 14, 14, 384)   0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, 14, 14, 384)   0           batch_normalization_93[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, 14, 14, 192)   576         conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, 14, 14, 320)   0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 14, 14, 768)   0           activation_88[0][0]              \n",
      "                                                                   activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 14, 14, 768)   0           activation_92[0][0]              \n",
      "                                                                   activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, 14, 14, 192)   0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 14, 14, 2048)  0           activation_86[0][0]              \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_2[0][0]              \n",
      "                                                                   activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)        (None, 18)            158162256   mixed10[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 164,242,320\n",
      "Trainable params: 164,235,792\n",
      "Non-trainable params: 6,528\n",
      "____________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 401408)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 401408)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 394)               158155146 \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 394)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 18)                7110      \n",
      "=================================================================\n",
      "Total params: 158,162,256\n",
      "Trainable params: 158,162,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.layers[-1].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1772/1772 [==============================] - 8s     \n",
      "(1.3571149046211157, 0.55925507927586748)\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# model.compile(optimizer=keras.optimizers.Adam(lr=params[0], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "#                   loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# loss, acc = model.evaluate(validation_data, validation_labels, batch_size=32, verbose=1, sample_weight=None)\n",
    "# print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1e-07, 394, 0.7, 0.7)\n",
      "Train on 14313 samples, validate on 1772 samples\n",
      "Epoch 1/2\n",
      "14272/14313 [============================>.] - ETA: 0s - loss: 1.3443 - acc: 0.6021Epoch 00000: val_acc improved from -inf to 0.53499, saving model to ../model/inceptionv3_500_part3/temp_weights_inceptionv3_500_part3.h5\n",
      "14313/14313 [==============================] - 171s - loss: 1.3451 - acc: 0.6020 - val_loss: 1.4311 - val_acc: 0.5350\n",
      "Epoch 2/2\n",
      "14272/14313 [============================>.] - ETA: 0s - loss: 1.1943 - acc: 0.6298Epoch 00001: val_acc improved from 0.53499 to 0.53668, saving model to ../model/inceptionv3_500_part3/temp_weights_inceptionv3_500_part3.h5\n",
      "14313/14313 [==============================] - 167s - loss: 1.1949 - acc: 0.6298 - val_loss: 1.4038 - val_acc: 0.5367\n",
      "1772/1772 [==============================] - 8s     \n",
      "{0.53668171584471625: (1.4037868091268948, 0.53668171584471625, (1e-07, 394, 0.7, 0.7))}\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "history = dict()\n",
    "for i in range(1):\n",
    "    best_acc = 0\n",
    "    \n",
    "    #0:lr,1:dense middle,2:dropout1, 3:dropout2\n",
    "    params=(10**np.random.uniform(low=-5, high=-1), \\\n",
    "            np.random.randint(low = 50, high=800), \\\n",
    "            np.random.uniform(low=0.3,high=0.8),\\\n",
    "            np.random.uniform(low=0.3,high=0.8))\n",
    "    params =(1.0e-07, 394, 0.7, 0.7)\n",
    "    print(params)\n",
    "    \n",
    "    top_model=Sequential()\n",
    "    top_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    top_model.add(Dropout(params[2]))\n",
    "    top_model.add(Dense(params[1], activation='relu'))\n",
    "    top_model.add(Dropout(params[2]))\n",
    "    top_model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "    top_model.load_weights(best_weight_path_part2)\n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=params[0], beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    weight_path = os.path.join(weight_dir, \"temp_weights_%s.h5\"%pretrained_model)\n",
    "    best_weight_path = os.path.join(weight_dir, \"best_weights_%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True)\n",
    "    stopper = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels),callbacks=[checkpointer,stopper])\n",
    "    model.load_weights(weight_path)\n",
    "    loss, acc = model.evaluate(validation_data, validation_labels, batch_size=32, verbose=1, sample_weight=None)\n",
    "    if acc>best_acc:\n",
    "        model.save_weights(best_weight_path)\n",
    "    history[acc] = (loss, acc, params)\n",
    "    \n",
    "print(history)\n",
    "pickle.dump(history, open(os.path.join(weight_dir,'history_%s.p'%pretrained_model),'w'))\n",
    "\n",
    "# model.save_weights(top_model_weights_path,overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 768/1772 [============>.................] - ETA: 4s"
     ]
    }
   ],
   "source": [
    "model.load_weights(best_weight_path)\n",
    "model.evaluate(validation_data, validation_labels, batch_size=32, verbose=1, sample_weight=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.812165600514552, 0.15204678362573099]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, test_labels, batch_size=32, verbose=1, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "weight_dir = \"../model/%s\"%pretrained_model\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "weight_path = os.path.join(weight_dir, \"temp_weights_%s.h5\"%pretrained_model)\n",
    "history = pickle.load(open(os.path.join(weight_dir,'history_%s.p'%pretrained_model),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.54627539530295555: (1.9093075596452029,\n",
       "  0.54627539530295555,\n",
       "  (9.872134816612904e-05, 653, 0.40977067265920386, 0.7121187929915329))}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
