{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "#weights_path = '../model/vgg16_weights.h5'\n",
    "top_model_weights_path = '../model/bottleneck_fc_model.h5'\n",
    "#top_model_weights_path = '../model/fc_model.h5'\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "#full\n",
    "#train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "#validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "#nb_train_samples = 14313\n",
    "#nb_validation_samples = 1772\n",
    "#total_num_classes = 18\n",
    "\n",
    "#small\n",
    "train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "nb_train_samples = 1462\n",
    "nb_validation_samples = 167\n",
    "total_num_classes = 18\n",
    "\n",
    "#verysmall\n",
    "#train_data_dir = '../data/verysmall/train'\n",
    "#validation_data_dir = '../data/verysmall/val'\n",
    "#nb_train_samples = 144 #157\n",
    "#nb_validation_samples = 16 #18\n",
    "#total_num_classes = 2\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "#top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='sigmoid'))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "# model.add(top_model)\n",
    "\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_weight_path = \"../model/best.h5\"\n",
    "best_acc = 0\n",
    "\n",
    "def get_model_val_acc(a_weight_path):\n",
    "    #sanity check that the saved best_weight_path contains weights that gets you an accuracy of best_acc\n",
    "    sanity_val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    sanity_val_generator = sanity_val_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    model.load_weights(a_weight_path)\n",
    "\n",
    "    sanity_loss, sanity_acc = model.evaluate_generator(generator = sanity_val_generator, steps = nb_validation_samples // batch_size)\n",
    "    print(\"best val loss check = \" + str(sanity_loss))\n",
    "    print(\"best val acc check = \" + str(sanity_acc))\n",
    "    \n",
    "    return sanity_acc\n",
    "\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        global best_acc\n",
    "        current_acc = logs.get('val_acc')\n",
    "        \n",
    "        if current_acc > best_acc:\n",
    "            print(\"\\n\\na better current_acc = \" + str(current_acc) + \"\\n\\n\")\n",
    "            best_acc = current_acc\n",
    "            model.save_weights(best_weight_path,overwrite=True)\n",
    "\n",
    "\n",
    "def run_with_parameters(frozen_layers = 25, lr = 1e-4, momentum = 0.9, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, best_acc = 0):\n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True;\n",
    "    \n",
    "    for layer in model.layers[:frozen_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    pretrained_model = \"temp_name\"\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    param_names = \"frozen_layers_\" + str(frozen_layers) + \"_lr_\" + str(lr) + \"_momentum_\" + str(momentum)\n",
    "    weight_path = os.path.join(weight_dir, param_names + \"_best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "    history = AccuracyHistory()\n",
    "    \n",
    "    # fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples,\n",
    "        callbacks=[checkpointer])\n",
    "#        callbacks=[checkpointer, history])\n",
    "    \n",
    "    a_new_acc = get_model_val_acc(weight_path)\n",
    "    if a_new_acc > best_acc:\n",
    "        model.load_weights(weight_path)\n",
    "        model.save_weights(best_weight_path)\n",
    "        best_acc = a_new_acc\n",
    "    \n",
    "    #model.load_weights(weight_path)\n",
    "    #validation_labels = np.array([0]*8+[1]*10+[2]*11+[3]*5+[4]*11+[5]*6+[6]*8+[7]*8+[8]*9+[9]*12+[10]*7+[11]*10+[12]*14+[13]*5+[14]*11+[15]*11+[16]*12+[17]*9)\n",
    "    #loss, acc = model.evaluate(x = validation_generator, y = validation_labels, batch_size=batch_size, verbose=1, sample_weight=None)\n",
    "    #if acc > best_acc:\n",
    "    #    model.save_weights(weight_path)\n",
    "        \n",
    "    #return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "frozen_layers_val = 25\n",
      "lr_val = 0.0001\n",
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Epoch 1/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7749 - acc: 0.1507Epoch 00000: val_acc improved from -inf to 0.20378, saving model to ../model/temp_name/frozen_layers_25_lr_0.0001_momentum_0.9_best_weightstemp_name.h5\n",
      "91/91 [==============================] - 40s - loss: 2.7672 - acc: 0.1525 - val_loss: 2.5888 - val_acc: 0.2038\n",
      "Epoch 2/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7370 - acc: 0.1725Epoch 00001: val_acc did not improve\n",
      "91/91 [==============================] - 39s - loss: 2.7402 - acc: 0.1719 - val_loss: 2.5861 - val_acc: 0.2034\n",
      "Found 167 images belonging to 18 classes.\n",
      "best val acc check = 2.5705360651\n",
      "best val acc check = 0.2125\n",
      "\n",
      "\n",
      "frozen_layers_val = 25\n",
      "lr_val = 1e-05\n",
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Epoch 1/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7993 - acc: 0.1681Epoch 00000: val_acc improved from -inf to 0.20339, saving model to ../model/temp_name/frozen_layers_25_lr_1e-05_momentum_0.9_best_weightstemp_name.h5\n",
      "91/91 [==============================] - 40s - loss: 2.8004 - acc: 0.1669 - val_loss: 2.5875 - val_acc: 0.2034\n",
      "Epoch 2/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7794 - acc: 0.1657Epoch 00001: val_acc did not improve\n",
      "91/91 [==============================] - 39s - loss: 2.7791 - acc: 0.1646 - val_loss: 2.5882 - val_acc: 0.2022\n",
      "Found 167 images belonging to 18 classes.\n",
      "best val acc check = 2.55662858486\n",
      "best val acc check = 0.20625\n",
      "\n",
      "\n",
      "\n",
      "best val acc = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:85: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=91, epochs=2, callbacks=[<keras.ca..., validation_steps=167)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frozen_layers_arr = [25]\n",
    "lr_arr = [1e-4, 1e-5]\n",
    "momentum_arr = [0.9]\n",
    "shear_range_arr = [0.2]\n",
    "zoom_range_arr = [0.2]\n",
    "horizontal_flip_arr = [True]\n",
    "\n",
    "for frozen_layers_val in frozen_layers_arr:\n",
    "    for lr_val in lr_arr:\n",
    "        print(\"\\n\")\n",
    "        print(\"frozen_layers_val = \" + str(frozen_layers_val))\n",
    "        print(\"lr_val = \" + str(lr_val))\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        new_weight_path = run_with_parameters(frozen_layers = frozen_layers_val, lr = lr_val)\n",
    "        \n",
    "        print(\"new_weight_path = \" + new_weight_path)\n",
    "        model.load_weights(new_weight_path)\n",
    "        \n",
    "        validation_data = np.load(open('../model/bottleneck_features_validation.npy'))\n",
    "        validation_labels = np.array([0]*8+[1]*10+[2]*11+[3]*5+[4]*11+[5]*6+[6]*8+[7]*8+[8]*9+[9]*12+[10]*7+[11]*10+[12]*14+[13]*5+[14]*11+[15]*11+[16]*12+[17]*9)\n",
    "        \n",
    "        print(validation_data.shape)\n",
    "        print(validation_labels.shape)\n",
    "        new_acc = model.evaluate(x=, y=, batch_size=batch_size, verbose=1)\n",
    "        print(\"accuracy = \" + str(new_acc))\n",
    "        os.rename(new_weight_path, new_weight_path + \"_acc_\" + str(new_acc))\n",
    "        \"\"\"\n",
    "        \n",
    "        new_acc = run_with_parameters(frozen_layers = frozen_layers_val, lr = lr_val, best_acc = best_acc)\n",
    "        #if new_acc > best_acc:\n",
    "        #    best_acc = new_acc\n",
    "        \n",
    "        #if new_acc > best_acc:\n",
    "            \n",
    "\n",
    "#print(\"\\n\\n\\nbest val acc = \" + str(best_acc))\n",
    "\n",
    "#run_with_parameters(frozen_layers = 25, lr = 1e-4, momentum = 0.9, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 167 images belonging to 18 classes.\n",
      "best val acc check = 2.5965811491\n",
      "best val acc check = 0.20625\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-31-011623786f41>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-011623786f41>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    return sanity_acc\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "#sanity check that the saved best_weight_path contains weights that gets you an accuracy of best_acc\n",
    "sanity_val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "sanity_val_generator = sanity_val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.load_weights(best_weight_path)\n",
    "\n",
    "sanity_loss, sanity_acc = model.evaluate_generator(generator = sanity_val_generator, steps = nb_validation_samples // batch_size)\n",
    "print(\"best val loss check = \" + str(sanity_loss))\n",
    "print(\"best val acc check = \" + str(sanity_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
