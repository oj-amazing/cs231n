{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_acc = 0\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "best_weight_path = \"../model/best.h5\"\n",
    "best_acc = 0\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "#top_model_weights_path = '../model/bottleneck_fc_model.h5'\n",
    "top_model_weights_path = '../model/bottleneck_fc_model_inceptionv3_500_val_acc_4791.h5'\n",
    "#top_model_weights_path = '../model/fc_model.h5'\n",
    "img_width, img_height = 500, 500\n",
    "\n",
    "#full\n",
    "train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "nb_train_samples = 14313\n",
    "nb_validation_samples = 1772\n",
    "total_num_classes = 18\n",
    "\n",
    "#small\n",
    "#train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "#validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "#test_data_dir = '../data/Pandora18K_small_train_val_test_split/test'\n",
    "#nb_train_samples = 1462\n",
    "#nb_validation_samples = 167\n",
    "#total_num_classes = 18\n",
    "\n",
    "#verysmall\n",
    "#train_data_dir = '../data/verysmall/train'\n",
    "#validation_data_dir = '../data/verysmall/val'\n",
    "#nb_train_samples = 144 #157\n",
    "#nb_validation_samples = 16 #18\n",
    "#total_num_classes = 2\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "print(\"best_acc = \" + str(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Found 14313 images belonging to 18 classes.\n",
      "Found 1772 images belonging to 18 classes.\n",
      "Found 171 images belonging to 18 classes.\n",
      "sanity_acc = 0.515909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:41: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# prepare data augmentation configuration\\ntrain_datagen = ImageDataGenerator(\\n    rescale=1. / 255,\\n    shear_range=0.2,\\n    zoom_range=0.2,\\n    horizontal_flip=True)\\n\\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\\n\\ntrain_generator = train_datagen.flow_from_directory(\\n    train_data_dir,\\n    target_size=(img_height, img_width),\\n    batch_size=batch_size,\\n    class_mode='categorical')\\n\\nvalidation_generator = test_datagen.flow_from_directory(\\n    validation_data_dir,\\n    target_size=(img_height, img_width),\\n    batch_size=batch_size,\\n    class_mode='categorical')\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_width,img_height,3))\n",
    "#base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "#top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='sigmoid'))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='softmax'))\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "#top_model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.6))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(.6))\n",
    "top_model.add(Dense(18, activation='softmax'))\n",
    "\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "# model.add(top_model)\n",
    "\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-5, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "valid_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_datagen  = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = nb_validation_samples // batch_size)\n",
    "print(\"sanity_acc = \" + str(sanity_acc))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        global best_acc\n",
    "        current_acc = logs.get('val_acc')\n",
    "        \n",
    "        if current_acc > best_acc:\n",
    "            print(\"\\n\\na better current_acc = \" + str(current_acc) + \"\\n\\n\")\n",
    "            best_acc = current_acc\n",
    "            model.save_weights(best_weight_path,overwrite=True)\n",
    "\"\"\"\n",
    "\n",
    "def run_with_parameters(frozen_layers = 25, lr = 1e-4, momentum = 0.9):\n",
    "    global best_acc\n",
    "    global best_weight_path\n",
    "    print(\"best val acc so far = \" + str(best_acc))\n",
    "    \n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True;\n",
    "    \n",
    "    for layer in model.layers[:frozen_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    pretrained_model = \"temp_name\"\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    param_names = \"frozen_layers_\" + str(frozen_layers) + \"_lr_\" + str(lr) + \"_momentum_\" + str(momentum)\n",
    "    weight_path = os.path.join(weight_dir, param_names + \"_best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=[checkpointer])\n",
    "    \n",
    "    #model.load_weights(weight_path)\n",
    "    _, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = nb_validation_samples // batch_size)\n",
    "    \n",
    "    print(\"sanity_acc = \"+ str(sanity_acc))\n",
    "    \n",
    "    if sanity_acc > best_acc:\n",
    "        print(\"updating best_acc by loading weights from \" + weight_path)\n",
    "        model.load_weights(weight_path)\n",
    "        model.save_weights(best_weight_path, overwrite = True)\n",
    "        best_acc = sanity_acc\n",
    "    \n",
    "    print(\"best val acc so far = \" + str(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "lr_val = 0.000207014464829\n",
      "best val acc so far = 0\n",
      "Epoch 1/1\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.8044 - acc: 0.1681Epoch 00000: val_acc improved from -inf to 0.18750, saving model to ../model/temp_name/frozen_layers_25_lr_0.000207014464829_momentum_0.9_best_weightstemp_name.h5\n",
      "91/91 [==============================] - 16s - loss: 2.8043 - acc: 0.1676 - val_loss: 2.6641 - val_acc: 0.1875\n",
      "sanity_acc = 0.192052980725\n",
      "updating best_acc by loading weights from ../model/temp_name/frozen_layers_25_lr_0.000207014464829_momentum_0.9_best_weightstemp_name.h5\n",
      "best val acc so far = 0.192052980725\n",
      "\n",
      "\n",
      "lr_val = 0.0362757856317\n",
      "best val acc so far = 0.192052980725\n",
      "Epoch 1/1\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7731 - acc: 0.1671Epoch 00000: val_acc improved from -inf to 0.19205, saving model to ../model/temp_name/frozen_layers_25_lr_0.0362757856317_momentum_0.9_best_weightstemp_name.h5\n",
      "91/91 [==============================] - 16s - loss: 2.7772 - acc: 0.1653 - val_loss: 2.6919 - val_acc: 0.1921\n",
      "sanity_acc = 0.21854304695\n",
      "updating best_acc by loading weights from ../model/temp_name/frozen_layers_25_lr_0.0362757856317_momentum_0.9_best_weightstemp_name.h5\n",
      "best val acc so far = 0.21854304695\n",
      "\n",
      "\n",
      "lr_val = 0.000679879756745\n",
      "best val acc so far = 0.21854304695\n",
      "Epoch 1/1\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.8099 - acc: 0.1660Epoch 00000: val_acc improved from -inf to 0.19868, saving model to ../model/temp_name/frozen_layers_25_lr_0.000679879756745_momentum_0.9_best_weightstemp_name.h5\n",
      "91/91 [==============================] - 16s - loss: 2.8052 - acc: 0.1662 - val_loss: 2.6245 - val_acc: 0.1987\n",
      "sanity_acc = 0.185430463576\n",
      "best val acc so far = 0.21854304695\n",
      "\n",
      "\n",
      "lr_val = 0.0298867128802\n",
      "best val acc so far = 0.21854304695\n",
      "Epoch 1/1\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.8207 - acc: 0.1822Epoch 00000: val_acc improved from -inf to 0.18543, saving model to ../model/temp_name/frozen_layers_25_lr_0.0298867128802_momentum_0.9_best_weightstemp_name.h5\n",
      "91/91 [==============================] - 16s - loss: 2.8222 - acc: 0.1802 - val_loss: 2.7027 - val_acc: 0.1854\n",
      "sanity_acc = 0.185430463576\n",
      "best val acc so far = 0.21854304695\n",
      "\n",
      "\n",
      "lr_val = 8.28846351577e-05\n",
      "best val acc so far = 0.21854304695\n",
      "Epoch 1/1\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.8033 - acc: 0.1706Epoch 00000: val_acc improved from -inf to 0.21192, saving model to ../model/temp_name/frozen_layers_25_lr_8.28846351577e-05_momentum_0.9_best_weightstemp_name.h5\n",
      "91/91 [==============================] - 16s - loss: 2.8055 - acc: 0.1687 - val_loss: 2.6316 - val_acc: 0.2119\n",
      "sanity_acc = 0.22516556321\n",
      "updating best_acc by loading weights from ../model/temp_name/frozen_layers_25_lr_8.28846351577e-05_momentum_0.9_best_weightstemp_name.h5\n",
      "best val acc so far = 0.22516556321\n",
      "\n",
      "\n",
      "\n",
      "best val acc = 0.22516556321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frozen_layers_arr = [25]\n",
    "lr_arr = [1e-4, 1e-5, 1e-2, 1e-6]\n",
    "momentum_arr = [0.9]\n",
    "shear_range_arr = [0.2]\n",
    "zoom_range_arr = [0.2]\n",
    "horizontal_flip_arr = [True]\n",
    "\n",
    "#0:lr,1:dense middle,2:dropout1, 3:dropout2\n",
    "#params=(10**np.random.uniform(low=-5, high=-1),np.random.randint(low = 50, high=800),np.random.uniform(low=0.3,high=0.8), np.random.uniform(low=0.3,high=0.8))\n",
    "\n",
    "for i in range(5):\n",
    "    frozen_layers_val = 25#np.random.randint(low = 25, high=25)\n",
    "    lr_val = 10**np.random.uniform(low=-5, high=-1)\n",
    "    print(\"\\n\")\n",
    "    print(\"lr_val = \" + str(lr_val))\n",
    "\n",
    "    run_with_parameters(frozen_layers = frozen_layers_val, lr = lr_val)\n",
    "            \n",
    "\n",
    "print(\"\\n\\n\\nbest val acc = \" + str(best_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best val loss check = 2.66694613131\n",
      "best val acc check = 0.179640718563\n"
     ]
    }
   ],
   "source": [
    "#sanity check that the saved best_weight_path contains weights that gets you an accuracy of best_acc\n",
    "#sanity_val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "#sanity_val_generator = sanity_val_datagen.flow_from_directory(\n",
    "#    validation_data_dir,\n",
    "#    target_size=(img_width, img_height),\n",
    "#    batch_size=batch_size,\n",
    "#    class_mode='categorical')\n",
    "\n",
    "model.load_weights(best_weight_path)\n",
    "\n",
    "sanity_loss, sanity_acc = model.evaluate_generator(generator = validation_generator, steps = (nb_validation_samples // batch_size)+1)\n",
    "print(\"best val loss check = \" + str(sanity_loss))\n",
    "print(\"best val acc check = \" + str(sanity_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
