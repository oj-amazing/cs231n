{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Model\n",
    "import os\n",
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# path to the model weights files.\n",
    "weights_path = '../keras/examples/vgg16_weights.h5'\n",
    "#weights_path = '../model/vgg16_weights.h5'\n",
    "top_model_weights_path = '../model/bottleneck_fc_model.h5'\n",
    "#top_model_weights_path = '../model/fc_model.h5'\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "#full\n",
    "#train_data_dir = '../data/Pandora18K_train_val_test_split/train'\n",
    "#validation_data_dir = '../data/Pandora18K_train_val_test_split/val'\n",
    "#nb_train_samples = 14313\n",
    "#nb_validation_samples = 1772\n",
    "#total_num_classes = 18\n",
    "\n",
    "#small\n",
    "train_data_dir = '../data/Pandora18K_small_train_val_test_split/train'\n",
    "validation_data_dir = '../data/Pandora18K_small_train_val_test_split/val'\n",
    "nb_train_samples = 1462\n",
    "nb_validation_samples = 167\n",
    "total_num_classes = 18\n",
    "\n",
    "#verysmall\n",
    "#train_data_dir = '../data/verysmall/train'\n",
    "#validation_data_dir = '../data/verysmall/val'\n",
    "#nb_train_samples = 144 #157\n",
    "#nb_validation_samples = 16 #18\n",
    "#total_num_classes = 2\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:33: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"se..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the VGG16 network\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "\"\"\"\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "#top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='sigmoid'))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1024, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(total_num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "# model.add(top_model)\n",
    "\n",
    "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_weight_path = \"../model/best.h5\"\n",
    "best_acc = 0\n",
    "\n",
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        global best_acc\n",
    "        current_acc = logs.get('val_acc')\n",
    "        \n",
    "        if current_acc > best_acc:\n",
    "            print(\"\\n\\na better current_acc = \" + str(current_acc) + \"\\n\\n\")\n",
    "            best_acc = current_acc\n",
    "            model.save_weights(best_weight_path,overwrite=True)\n",
    "            #model.save_weights(best_weight_path)\n",
    "            \n",
    "        \n",
    "    \n",
    "    #    def on_train_begin(self, logs={}):\n",
    "    #        self.accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "def run_with_parameters(frozen_layers = 25, lr = 1e-4, momentum = 0.9, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, best_acc = 0):\n",
    "    # set the first 25 layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True;\n",
    "    \n",
    "    for layer in model.layers[:frozen_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=lr, momentum=momentum),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=shear_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    \n",
    "    pretrained_model = \"temp_name\"\n",
    "    weight_dir = \"../model/%s\"%pretrained_model\n",
    "    if not os.path.exists(weight_dir):\n",
    "        os.makedirs(weight_dir)\n",
    "    param_names = \"frozen_layers_\" + str(frozen_layers) + \"_lr_\" + str(lr) + \"_momentum_\" + str(momentum)\n",
    "    weight_path = os.path.join(weight_dir, param_names + \"_best_weights%s.h5\"%pretrained_model)\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(filepath=weight_path, verbose=1,monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "    history = AccuracyHistory()\n",
    "    \n",
    "    # fine-tune the model\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples,\n",
    "        callbacks=[checkpointer, history])\n",
    "    \n",
    "    #model.load_weights(weight_path)\n",
    "    #validation_labels = np.array([0]*8+[1]*10+[2]*11+[3]*5+[4]*11+[5]*6+[6]*8+[7]*8+[8]*9+[9]*12+[10]*7+[11]*10+[12]*14+[13]*5+[14]*11+[15]*11+[16]*12+[17]*9)\n",
    "    #loss, acc = model.evaluate(x = validation_generator, y = validation_labels, batch_size=batch_size, verbose=1, sample_weight=None)\n",
    "    #if acc > best_acc:\n",
    "    #    model.save_weights(weight_path)\n",
    "        \n",
    "    #return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "frozen_layers_val = 25\n",
      "lr_val = 0.0001\n",
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Epoch 1/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7333 - acc: 0.1646Epoch 00000: val_acc improved from -inf to 0.20418, saving model to ../model/temp_name/frozen_layers_25_lr_0.0001_momentum_0.9_best_weightstemp_name.h5\n",
      "\n",
      "\n",
      "a better current_acc = 0.204178163708\n",
      "\n",
      "\n",
      "91/91 [==============================] - 40s - loss: 2.7340 - acc: 0.1641 - val_loss: 2.5869 - val_acc: 0.2042\n",
      "Epoch 2/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7653 - acc: 0.1671Epoch 00001: val_acc did not improve\n",
      "91/91 [==============================] - 39s - loss: 2.7567 - acc: 0.1701 - val_loss: 2.5878 - val_acc: 0.2030\n",
      "\n",
      "\n",
      "frozen_layers_val = 25\n",
      "lr_val = 1e-05\n",
      "Found 1462 images belonging to 18 classes.\n",
      "Found 167 images belonging to 18 classes.\n",
      "Epoch 1/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7818 - acc: 0.1424Epoch 00000: val_acc improved from -inf to 0.20497, saving model to ../model/temp_name/frozen_layers_25_lr_1e-05_momentum_0.9_best_weightstemp_name.h5\n",
      "\n",
      "\n",
      "a better current_acc = 0.204966496249\n",
      "\n",
      "\n",
      "91/91 [==============================] - 41s - loss: 2.7889 - acc: 0.1435 - val_loss: 2.5848 - val_acc: 0.2050\n",
      "Epoch 2/2\n",
      "90/91 [============================>.] - ETA: 0s - loss: 2.7680 - acc: 0.1810Epoch 00001: val_acc improved from 0.20497 to 0.20497, saving model to ../model/temp_name/frozen_layers_25_lr_1e-05_momentum_0.9_best_weightstemp_name.h5\n",
      "\n",
      "\n",
      "a better current_acc = 0.204966496349\n",
      "\n",
      "\n",
      "91/91 [==============================] - 40s - loss: 2.7689 - acc: 0.1811 - val_loss: 2.5856 - val_acc: 0.2050\n",
      "\n",
      "\n",
      "\n",
      "best val acc = 0.204966496349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:75: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=91, epochs=2, callbacks=[<keras.ca..., validation_steps=167)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frozen_layers_arr = [25]\n",
    "lr_arr = [1e-4, 1e-5]\n",
    "momentum_arr = [0.9]\n",
    "shear_range_arr = [0.2]\n",
    "zoom_range_arr = [0.2]\n",
    "horizontal_flip_arr = [True]\n",
    "\n",
    "for frozen_layers_val in frozen_layers_arr:\n",
    "    for lr_val in lr_arr:\n",
    "        print(\"\\n\")\n",
    "        print(\"frozen_layers_val = \" + str(frozen_layers_val))\n",
    "        print(\"lr_val = \" + str(lr_val))\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        new_weight_path = run_with_parameters(frozen_layers = frozen_layers_val, lr = lr_val)\n",
    "        \n",
    "        print(\"new_weight_path = \" + new_weight_path)\n",
    "        model.load_weights(new_weight_path)\n",
    "        \n",
    "        validation_data = np.load(open('../model/bottleneck_features_validation.npy'))\n",
    "        validation_labels = np.array([0]*8+[1]*10+[2]*11+[3]*5+[4]*11+[5]*6+[6]*8+[7]*8+[8]*9+[9]*12+[10]*7+[11]*10+[12]*14+[13]*5+[14]*11+[15]*11+[16]*12+[17]*9)\n",
    "        \n",
    "        print(validation_data.shape)\n",
    "        print(validation_labels.shape)\n",
    "        new_acc = model.evaluate(x=, y=, batch_size=batch_size, verbose=1)\n",
    "        print(\"accuracy = \" + str(new_acc))\n",
    "        os.rename(new_weight_path, new_weight_path + \"_acc_\" + str(new_acc))\n",
    "        \"\"\"\n",
    "        \n",
    "        new_acc = run_with_parameters(frozen_layers = frozen_layers_val, lr = lr_val, best_acc = best_acc)\n",
    "        if new_acc > best_acc:\n",
    "            best_acc = new_acc\n",
    "        \n",
    "        #if new_acc > best_acc:\n",
    "            \n",
    "\n",
    "print(\"\\n\\n\\nbest val acc = \" + str(best_acc))\n",
    "\n",
    "#run_with_parameters(frozen_layers = 25, lr = 1e-4, momentum = 0.9, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 167 images belonging to 18 classes.\n",
      "best val acc check = 2.5741029501\n",
      "best val acc check = 0.20625\n"
     ]
    }
   ],
   "source": [
    "#sanity check that the saved best_weight_path contains weights that gets you an accuracy of best_acc\n",
    "sanity_val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "sanity_val_generator = sanity_val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.load_weights(best_weight_path)\n",
    "\n",
    "sanity_loss, sanity_acc = model.evaluate_generator(generator = sanity_val_generator, steps = nb_validation_samples // batch_size)\n",
    "print(\"best val acc check = \" + str(sanity_loss))\n",
    "print(\"best val acc check = \" + str(sanity_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
