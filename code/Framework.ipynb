{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As usual, a bit of setup\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from PIL import Image\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_Pandora18K(data_dir = '../dataset/Pandora_18k_flat_and_resized'):\n",
    "    \n",
    "    i = 0\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        path = root.split(os.sep)\n",
    "        for file in files:\n",
    "            if '.jpg' in str(file).lower(): # an image file\n",
    "                file_path = os.path.join(root,file)\n",
    "\n",
    "                # Get image\n",
    "                imagedata = imread(file_path)\n",
    "                assert imagedata.shape == (500, 500, 3)\n",
    "                X_data.append(imagedata)\n",
    "                \n",
    "                # Get class\n",
    "                correct_class = -1\n",
    "                if \"01_Byzantin_Iconography\" in root:\n",
    "                    correct_class = 1\n",
    "                elif \"02_Early_Renaissance\" in root:\n",
    "                    correct_class = 2\n",
    "                elif \"03_Northern_Renaissance\" in root:\n",
    "                    correct_class = 3\n",
    "                elif \"04_High_Renaissance\" in root:\n",
    "                    correct_class = 4\n",
    "                elif \"05_Baroque\" in root:\n",
    "                    correct_class = 5\n",
    "                elif \"06_Rococo\" in root:\n",
    "                    correct_class = 6\n",
    "                elif \"07_Romanticism\" in root:\n",
    "                    correct_class = 7\n",
    "                elif \"08_Realism\" in root:\n",
    "                    correct_class = 8\n",
    "                elif \"09_Impressionism\" in root:\n",
    "                    correct_class = 9\n",
    "                elif \"10_Post_Impressionism\" in root:\n",
    "                    correct_class = 10\n",
    "                elif \"11_Expressionism\" in root:\n",
    "                    correct_class = 11\n",
    "                elif \"12_Symbolism\" in root:\n",
    "                    correct_class = 12\n",
    "                elif \"13_Fauvism\" in root:\n",
    "                    correct_class = 13\n",
    "                elif \"14_Cubism\" in root:\n",
    "                    correct_class = 14\n",
    "                elif \"15_Surrealism\" in root:\n",
    "                    correct_class = 15\n",
    "                elif \"16_AbstractArt\" in root:\n",
    "                    correct_class = 16\n",
    "                elif \"17_NaiveArt\" in root:\n",
    "                    correct_class = 17\n",
    "                elif \"18_PopArt\" in root:\n",
    "                    correct_class = 18\n",
    "                \n",
    "                assert correct_class != -1\n",
    "                Y_data.append(correct_class)\n",
    "                \n",
    "                \"\"\"\n",
    "                i = i + 1\n",
    "\n",
    "                if i >= 30: #this should be all of them, do the shuffling and subsampling below\n",
    "                    X_data_arr = np.array(X_data)\n",
    "                    Y_data_arr = np.array(Y_data)\n",
    "                    return X_data_arr, Y_data_arr\n",
    "                \"\"\"\n",
    "    X_data_arr = np.array(X_data)\n",
    "    Y_data_arr = np.array(Y_data)\n",
    "    return X_data_arr, Y_data_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pandora18k data...\n",
      "Shuffling Pandora18k data...\n",
      "X_data.shape\n",
      "(17876, 500, 500, 3)\n",
      "Y_data.shape\n",
      "(17876,)\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "data_dir = '../dataset/Pandora_18k_flat_and_resized'\n",
    "#17876 images total\n",
    "\n",
    "#grab data\n",
    "print(\"Loading Pandora18k data...\")\n",
    "X_data, Y_data = load_Pandora18K(data_dir)\n",
    "\n",
    "#shuffle x and y data together\n",
    "print(\"Shuffling Pandora18k data...\")\n",
    "X_data, Y_data = unison_shuffled_copies(X_data, Y_data)\n",
    "\n",
    "print(\"X_data.shape\")\n",
    "print(X_data.shape)\n",
    "print(\"Y_data.shape\")\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling get_data()...\n",
      "Subsampling training...\n",
      "Subsampling validation...\n",
      "Subsampling test...\n",
      "Train data shape:  (100, 500, 500, 3)\n",
      "Train labels shape:  (100,)\n",
      "Validation data shape:  (50, 500, 500, 3)\n",
      "Validation labels shape:  (50,)\n",
      "Test data shape:  (50, 500, 500, 3)\n",
      "Test labels shape:  (50,)\n"
     ]
    }
   ],
   "source": [
    "#def get_data(num_training=8000, num_validation=1876, num_test=8000): \n",
    "def sub_sample_data(num_training=100, num_validation=50, num_test=50): #test with 300 images total\n",
    "    \n",
    "    #training data subsample\n",
    "    print(\"Subsampling training...\")\n",
    "    mask = range(0, num_training)\n",
    "    X_train = X_data[mask]\n",
    "    y_train = Y_data[mask]\n",
    "    \n",
    "    #validation data subsample\n",
    "    print(\"Subsampling validation...\")\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_data[mask]\n",
    "    y_val = Y_data[mask]\n",
    "    \n",
    "    #test data subsample\n",
    "    print(\"Subsampling test...\")\n",
    "    mask = range(num_training + num_validation, num_training + num_validation + num_test)\n",
    "    X_test = X_data[mask]\n",
    "    y_test = Y_data[mask]\n",
    "    \n",
    "    \"\"\"\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    \n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    \n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \"\"\"\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "print(\"calling get_data()...\")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = sub_sample_data()\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 500, 500, 3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def style_model(img, y):\n",
    "    \"\"\"Generate class scores for img\n",
    "    \n",
    "    Inputs:\n",
    "    - img: Tensor of image [batch_size, 500, 500, 3]\n",
    "    - y: class [batch_size, 18]\n",
    "    \n",
    "    Returns:\n",
    "    Class scores [batch_size, 18].\n",
    "    \"\"\"\n",
    "    \n",
    "    dims = tf.shape(img)\n",
    "    batch_size = dims[0]\n",
    "    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=img,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"valid\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    #print(conv1)\n",
    "    \n",
    "    flat = tf.reshape(conv1, [batch_size, 7872512]) #496 * 496 * 32\n",
    "    \n",
    "    #print(flat)\n",
    "    \n",
    "    dense = tf.layers.dense(inputs=flat, units=18, activation=tf.nn.relu)\n",
    "\n",
    "    return dense\n",
    "\n",
    "y_out = style_model(X, y)\n",
    "\n",
    "# define our loss\n",
    "total_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_out)\n",
    "mean_loss = tf.reduce_mean(total_loss)\n",
    "\n",
    "# define our optimizer\n",
    "optimizer = tf.train.AdamOptimizer(5e-4) # select optimizer and set learning rate\n",
    "train_step = optimizer.minimize(mean_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Iteration 0: with minibatch training loss = 45 and accuracy of 0\n",
      "Epoch 1, Overall loss = nan and accuracy of 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG6lJREFUeJzt3XmUXnWd5/H3R4KAFBBZuiZANM6QkQGGLSViyzgVcEEa\nDSIijMoimu4eVLp1bEA9jR6absYFWweGnghIUJqCQZTIoIiYGo4LYoJhCYEhsighgmACKTYFPvPH\n/ZU+xJuqJ5XcelL1fF7nPKfu9rv3+wuc+tRdnt+VbSIiItb2kk4XEBERm6YERERE1EpARERErQRE\nRETUSkBEREStBERERNRKQESsJ0mWtFun64hoWgIiJjRJ90t6WtJQy+fcTtc1TNJekq6T9KikUb90\nlPCJTUkCIiaDt9nuafl8qNMFtfg9cAVwUqcLiVhfCYiYtCSdIOlHks6V9LikuyQd0rJ+Z0kLJP1W\n0nJJH2xZt5mkT0j6haQ1khZLmt6y+zdKukfSaknnSVJdDbbvtn0hsHQD+/ISSZ+S9ICkRyRdImm7\nsm5LSV+X9Fip52eSelv+De4tfbhP0ns2pI7oLgmImOxeC/wC2BE4A7hK0vZl3QDwILAzcBTwj5IO\nLus+ChwLHAZsC7wfeKplv4cDrwH2Bo4G3tJsNzihfGYD/xboAYYvpR0PbAdMB3YA/gp4WtLWwJeB\nt9reBvhzYEnDdcYkkoCIyeBb5S/n4c8HW9Y9Avyz7d/bvhy4G/iLcjbweuBU28/YXgJcABxX2n0A\n+FQ5A7DtW20/1rLfs22vtv1LYCGwb8N9fA9wju17bQ8BpwPHSJpCdRlrB2A328/bXmz7idLuBWAv\nSVvZXml7g85korskIGIyOML21JbPV1rWrfCLR6R8gOqMYWfgt7bXrLVulzI9nerMY11+3TL9FNVf\n9E3amaq+YQ8AU4Be4GvAdcCApIckfVbS5rafBN5NdUaxUtL/kbR7w3XGJJKAiMlul7XuD7wCeKh8\ntpe0zVrrVpTpXwH/bnxKbMtDwCtb5l8BPAc8XM6OPmN7D6rLSIdTzoRsX2f7TcA04C7gK0S0KQER\nk92fAR+RtLmkdwH/AbjW9q+AHwP/VG7y7k31pNHXS7sLgDMlzVRlb0k7rO/BS9stgZeW+S0lbTFK\ns5eW7YY/mwGXAX8r6VWSeoB/BC63/Zyk2ZL+Y9nuCapLTi9I6pU0p9yLeBYYorrkFNGWKZ0uIGIj\n+Lak51vmr7f9jjL9U2Am8CjwMHBUy72EY4F/ofrrfBVwhu3vl3XnAFsA36O6wX0XMLzP9fFK4L6W\n+aepLg/NGKHN2vcJPghcRHWZ6UZgS6pLSh8u6/9N6ceuVCFwOdVlp52obrZfApjqBvVfj6EP0aWU\nFwbFZCXpBOADtg/qdC0RE1EuMUVERK0ERERE1MolpoiIqJUziIiIqDWhn2LacccdPWPGjDG1ffLJ\nJ9l66603bkGbuPS5O6TP3WFD+rx48eJHbe802nYTOiBmzJjBokWLxtR2cHCQ/v7+jVvQJi597g7p\nc3fYkD5LemD0rXKJKSIi1iEBERERtRIQERFRKwERERG1EhAREVErAREREbUSEBERUSsBERERtRIQ\nERFRKwERERG1EhAREVGrsYAo79K9WdKtkpZK+kxZfrGk+yQtKZ99y3JJ+rKk5ZJuk7R/U7VFRMTo\nmhys71ngYNtDkjYHfijpO2Xdx21fudb2b6V6d/BM4LXA+eVnRER0QGNnEK4MldnNy2ektxPNAS4p\n7W4Cpkqa1lR9ERExskbfKCdpM2AxsBtwnu1TJV0MvI7qDOMG4DTbz0q6Bjjb9g9L2xuAU20vWmuf\nc4G5AL29vbMGBgbGVNvQ0BA9PT1j69gElT53h/S5O2xIn2fPnr3Ydt+oG9pu/ANMBRYCewHTAAFb\nAPOBvy/bXAMc1NLmBqBvpP3OmjXLY7Vw4cIxt52o0ufukD53hw3pM7DIbfzuHpenmGyvLgFxqO2V\npcZnga8CB5TNVgDTW5rtWpZFREQHNPkU006SppbprYA3AXcN31eQJOAI4I7SZAFwXHma6UDgcdsr\nm6ovIiJG1uRTTNOA+eU+xEuAK2xfI+kHknaiusy0BPirsv21wGHAcuAp4MQGa4uIiFE0FhC2bwP2\nq1l+8Dq2N3ByU/VERMT6yTepIyKiVgIiIiJqJSAiIqJWAiIiImolICIiolYCIiIiaiUgIiKiVgIi\nIiJqJSAiIqJWAiIiImolICIiolYCIiIiaiUgIiKiVgIiIiJqJSAiIqJWAiIiImolICIiolYCIiIi\naiUgIiKiVgIiIiJqNRYQkraUdLOkWyUtlfSZsvxVkn4qabmkyyW9tCzfoswvL+tnNFVbRESMrskz\niGeBg23vA+wLHCrpQOC/A1+0vRuwCjipbH8SsKos/2LZLiIiOqSxgHBlqMxuXj4GDgauLMvnA0eU\n6TllnrL+EElqqr6IiBiZbDe3c2kzYDGwG3Ae8DngpnKWgKTpwHds7yXpDuBQ2w+Wdb8AXmv70bX2\nOReYC9Db2ztrYGBgTLUNDQ3R09Mzto5NUOlzd0ifu8OG9Hn27NmLbfeNtt2UMe29TbafB/aVNBX4\nJrD7RtjnPGAeQF9fn/v7+8e0n8HBQcbadqJKn7tD+twdxqPP4/IUk+3VwELgdcBUScPBtCuwokyv\nAKYDlPXbAY+NR30REfGnmnyKaady5oCkrYA3AcuoguKostnxwNVlekGZp6z/gZu8/hURESNq8hLT\nNGB+uQ/xEuAK29dIuhMYkPQPwM+BC8v2FwJfk7Qc+C1wTIO1RUTEKBoLCNu3AfvVLL8XOKBm+TPA\nu5qqJyIi1k++SR0REbUSEBERUSsBERERtRIQERFRKwERERG1EhAREVErAREREbUSEBERUSsBERER\ntRIQERFRKwERERG1EhAREVErAREREbUSEBERUSsBERERtRIQERFRKwERERG1EhAREVErAREREbUS\nEBERUSsBERERtRoLCEnTJS2UdKekpZJOKcs/LWmFpCXlc1hLm9MlLZd0t6S3NFVbRESMbkqD+34O\n+JjtWyRtAyyWdH1Z90Xbn2/dWNIewDHAnsDOwPcl/XvbzzdYY0RErENjZxC2V9q+pUyvAZYBu4zQ\nZA4wYPtZ2/cBy4EDmqovIiJGJtsjb1BdGvoqsAa4ANgPOM3299o+iDQDuBHYC/gocALwBLCI6ixj\nlaRzgZtsf720uRD4ju0r19rXXGAuQG9v76yBgYF2y3iRoaEhenp6xtR2okqfu0P63B02pM+zZ89e\nbLtv1A1tj/gBbi0/3wJcRXUJ6JbR2rW07wEWA0eW+V5gM6qzl7OAi8ryc4H3trS7EDhqpH3PmjXL\nY7Vw4cIxt52o0ufukD53hw3pM7DIbfz+bucSk8rPw4Cv2V7asmzkhtLmwDeAS21fVQLpYdvP234B\n+Ap/vIy0Apje0nzXsiwiIjqgnYBYLOl7VAFxXbnh/MJojSSJ6ixgme1zWpZPa9nsHcAdZXoBcIyk\nLSS9CpgJ3NxeNyIiYmNr5ymmk4B9gXttPyVpe+DENtq9HngfcLukJWXZJ4BjJe0LGLgf+EsA20sl\nXQHcSfUE1MnOE0wRER3TTkC8Dlhi+0lJ7wX2B740WiPbP6T+UtS1I7Q5i+q+REREdFg7l5jOB56S\ntA/wMeAXwCWNVhURER3XTkA8V+56zwHOtX0esE2zZUVERKe1c4lpjaTTqe4n/CdJLwE2b7asiIjo\ntHbOIN4NPAu83/avqR4//VyjVUVERMeNGhAlFC4FtpN0OPCM7dyDiIiY5EYNCElHU30f4V3A0cBP\nJR3VdGEREdFZ7dyD+CTwGtuPAEjaCfg+cOWIrSIiYkJr5x7ES4bDoXiszXYRETGBtXMG8V1J1wGX\nlfl3M8KX3SIiYnIYNSBsf1zSO6mGzgCYZ/ubzZYVERGd1tYb5Wx/g2pU1oiI6BLrDAhJa6gG1PuT\nVYBtb9tYVRER0XHrDAjbGU4jIqKL5WmkiIiolYCIiIhaCYiIiKiVgIiIiFrtjMV0pKR7JD0u6QlJ\nayQ9MR7FRURE57TzPYjPAm+zvazpYiIiYtPRziWmhxMOERHdZ6Qvyh1ZJhdJuhz4FtWLgwCwfdVI\nO5Y0nerd1b1UX7ibZ/tLkrYHLgdmAPcDR9teJUnAl4DDgKeAE2zfMsZ+RUTEBhrpEtPbWqafAt7c\nMm9gxIAAngM+ZvsWSdsAiyVdD5wA3GD7bEmnAacBpwJvBWaWz2uB88vPiIjogJG+SX3ihuzY9kpg\nZZleI2kZsAswB+gvm80HBqkCYg5wiW0DN0maKmla2U9ERIwzVb+PR9hAmg+cYnt1mX858AXb72/7\nINIM4EZgL+CXtqeW5QJW2Z4q6RrgbNs/LOtuAE61vWitfc0F5gL09vbOGhgYaLeMFxkaGqKnp2dM\nbSeq9Lk7pM/dYUP6PHv27MW2+0bbrp2nmPYeDgeAcr9gv3YLkdRDNRLs39h+osqEP+zLkkZOqLXY\nngfMA+jr63N/f//6NP+DwcFBxtp2okqfu0P63B3Go89tvVGunDUAUG4ytzVMuKTNqcLh0pab2g9L\nmlbWTwOG31a3Apje0nzXsiwiIjqgnYD4AvATSWdKOhP4MfC50RqVy0cXAstsn9OyagFwfJk+Hri6\nZflxqhwIPJ77DxERndPOG+UukbQIOLgsOtL2nW3s+/XA+4DbJS0pyz4BnA1cIekk4AHg6LLuWqpH\nXJdTPTW1QTfJIyJiw4waEJK+Zvt9wJ01y9ap3GzWOlYfUrO9gZNHqyciIsZHO5eY9mydkbQZMKuZ\nciIiYlOxzoCQdHp57ejeLYP0raG6qXz1utpFRMTksM6AsP1P5bWjn7O9re1tymcH26ePY40REdEB\n7dykPr085joT2LJl+Y1NFhYREZ3Vzk3qDwCnUH0vYQlwIPAT/vhUU0RETELt3KQ+BXgN8IDt2cB+\nwOqRm0RExETXTkA8Y/sZAElb2L4LeHWzZUVERKe1M2TGg5KmUr0P4npJq6i+4BYREZNYOzep31Em\nPy1pIbAd8N1Gq4qIiI5rd9C9/YGDqF4U9CPbv2u0qoiI6LhR70FI+nuqF/vsAOwIfFXSp5ouLCIi\nOqudM4j3APu03Kg+m+px139osrCIiOisdp5ieoiWL8gBW5D3NERETHrrPIOQ9D+o7jk8DiyVdH2Z\nfxNw8/iUFxERnTLSJabhd0EvBr7ZsnywsWoiImKTsc6AsD1/PAuJiIhNy0iXmK6wfbSk26kuLb2I\n7b0brSwiIjpqpEtMp5Sfh49HIRERsWkZ6RLTyvIzw2pERHShdr4od6SkeyQ93vJmuSfGo7iIiOic\ndr4H8Vng7ba3a3mz3LajNZJ0kaRHJN3RsuzTklZIWlI+h7WsO13Sckl3S3rL2LoTEREbSzsB8bDt\nZWPY98XAoTXLv2h73/K5FkDSHsAxwJ6lzf+UtNkYjhkRERtJO0NtLJJ0OdVw388OL7R91UiNbN8o\naUabdcwBBmw/C9wnaTlwANWb6yIiogPaCYhtgaeAN7csMzBiQIzgQ5KOo/oi3sdsrwJ2AW5q2ebB\nsuxPSJoLzAXo7e1lcHBwTEUMDQ2Nue1ElT53h/S5O4xHn9t5H8SJG/F45wNnUgXMmcAXgPevzw5s\nzwPmAfT19bm/v39MhQwODjLWthNV+twd0ufuMB59HumLcn9n+7MtYzK9iO2PrO/BbD/csv+vANeU\n2RXA9JZNdyUDAkZEdNRIZxDDN6YXjbDNepE0bfj7FcA7gOEnnBYA/yrpHGBnYCYZEDAioqNG+qLc\nt8vPMY3JJOkyoB/YUdKDwBlAv6R9qc5I7gf+shxjqaQrgDuB54CTbT8/luNGRMTGMeo9CEl9wCeB\nV7ZuP9pYTLaPrVl84QjbnwWcNVo9ERExPtp5iulS4OPA7cALzZYTERGbinYC4je2FzReSUREbFLa\nCYgzJF0A3MB6fFEuIiImtnYC4kRgd2Bz/niJaUO+KBcRERNAOwHxGtuvbrySiIjYpLQzWN+Py2B6\nERHRRdo5gzgQWCLpPqp7EAKcV45GRExu7QRE3ZDdERExybUzWF9eORoR0YXauQcRERFdKAERERG1\nEhAREVErAREREbUSEBERUSsBERERtRIQERFRKwERERG1EhAREVErAREREbUSEBERUSsBERERtRoL\nCEkXSXpE0h0ty7aXdL2ke8rPl5flkvRlScsl3SZp/6bqioiI9jR5BnExfzpU+GnADbZnUr3j+rSy\n/K3AzPKZC5zfYF0REdGGxgLC9o3Ab9daPAeYX6bnA0e0LL/ElZuAqZKmNVVbRESMTrab27k0A7jG\n9l5lfrXtqWVawCrbUyVdA5xt+4dl3Q3AqbYX1exzLtVZBr29vbMGBgbGVNvQ0BA9PT1jajtRpc/d\nIX3uDhvS59mzZy+23Tfadu28Ua4Rti1pvdPJ9jxgHkBfX5/7+/vHdPzBwUHG2naiSp+7Q/rcHcaj\nz+P9FNPDw5eOys9HyvIVwPSW7XYtyyIiokPGOyAWAMeX6eOBq1uWH1eeZjoQeNz2ynGuLSIiWjR2\niUnSZUA/sKOkB4EzgLOBKySdBDwAHF02vxY4DFgOPAWc2FRdERHRnsYCwvax61h1SM22Bk5uqpaI\niFh/+SZ1RETUSkBEREStBERERNRKQERERK0ERERE1EpARERErQRERETUSkBEREStBERERNRKQERE\nRK0ERERE1EpARERErQRERETUSkBEREStBERERNRKQERERK0ERERE1EpARERErQRERETUSkBERESt\nKZ04qKT7gTXA88BztvskbQ9cDswA7geOtr2qE/VFRERnzyBm297Xdl+ZPw24wfZM4IYyHxERHbIp\nXWKaA8wv0/OBIzpYS0RE15Pt8T+odB+wCjDwv2zPk7Ta9tSyXsCq4fm12s4F5gL09vbOGhgYGFMN\nQ0ND9PT0jLULE1L63B3S5+6wIX2ePXv24parN+tme9w/wC7l558BtwJvAFavtc2q0fYza9Ysj9XC\nhQvH3HaiSp+7Q/rcHTakz8Ait/G7uiOXmGyvKD8fAb4JHAA8LGkaQPn5SCdqi4iIyrgHhKStJW0z\nPA28GbgDWAAcXzY7Hrh6vGuLiIg/6sRjrr3AN6vbDEwB/tX2dyX9DLhC0knAA8DRHagtIiKKcQ8I\n2/cC+9Qsfww4ZLzriYiIepvSY64REbEJSUBEREStBERERNRKQERERK0ERERE1EpARERErQRERETU\nSkBEREStBERERNTqyBvlort85ttLufOhJzpy7NWrn+b8u3/SkWN3SvrcHbZ94Vn6+5s9Rs4gIiKi\nVs4gonFnvG3Pjh17cHCQ/v7Xdez4nZA+d4fBwcHGj5EziIiIqJWAiIiIWgmIiIiolYCIiIhaCYiI\niKiVgIiIiFoJiIiIqJWAiIiIWrLd6RrGTNJvgAfG2HxH4NGNWM5EkD53h/S5O2xIn19pe6fRNprQ\nAbEhJC2y3dfpOsZT+twd0ufuMB59ziWmiIiolYCIiIha3RwQ8zpdQAekz90hfe4Ojfe5a+9BRETE\nyLr5DCIiIkaQgIiIiFpdGRCSDpV0t6Tlkk7rdD1NkzRd0kJJd0paKumUTtc0HiRtJunnkq7pdC3j\nRdJUSVdKukvSMkmT+i06kv62/D99h6TLJG3Z6ZqaIOkiSY9IuqNl2faSrpd0T/n58o193K4LCEmb\nAecBbwX2AI6VtEdnq2rcc8DHbO8BHAic3AV9BjgFWNbpIsbZl4Dv2t4d2IdJ3H9JuwAfAfps7wVs\nBhzT2aoaczFw6FrLTgNusD0TuKHMb1RdFxDAAcBy2/fa/h0wAMzpcE2Nsr3S9i1leg3VL41dOltV\nsyTtCvwFcEGnaxkvkrYD3gBcCGD7d7ZXd7aqxk0BtpI0BXgZ8FCH62mE7RuB3661eA4wv0zPB47Y\n2MftxoDYBfhVy/yDTPJflq0kzQD2A37a2Uoa98/A3wEvdLqQcfQq4DfAV8ultQskbd3poppiewXw\neeCXwErgcdvf62xV46rX9soy/Wugd2MfoBsDomtJ6gG+AfyN7Sc6XU9TJB0OPGJ7cadrGWdTgP2B\n823vBzxJA5cdNhXlmvscqmDcGdha0ns7W1VnuPq+wkb/zkI3BsQKYHrL/K5l2aQmaXOqcLjU9lWd\nrqdhrwfeLul+qkuIB0v6emdLGhcPAg/aHj47vJIqMCarNwL32f6N7d8DVwF/3uGaxtPDkqYBlJ+P\nbOwDdGNA/AyYKelVkl5KdVNrQYdrapQkUV2XXmb7nE7X0zTbp9ve1fYMqv++P7A96f+ytP1r4FeS\nXl0WHQLc2cGSmvZL4EBJLyv/jx/CJL4pX2MBcHyZPh64emMfYMrG3uGmzvZzkj4EXEf11MNFtpd2\nuKymvR54H3C7pCVl2SdsX9vBmqIZHwYuLX/83Auc2OF6GmP7p5KuBG6helLv50zSITckXQb0AztK\nehA4AzgbuELSSVSvPTh6ox83Q21ERESdbrzEFBERbUhARERErQRERETUSkBEREStBERERNRKQMSk\nIento43OK2nn8mgkkk6QdO56HuMTbWxzsaSj1me/G5OkQUmNvsw+ukMCIiYN2wtsnz3KNg/Z3pBf\n3qMGxERWBr2LABIQMQFImlHeb3CxpP8n6VJJb5T0ozIW/gFluz+cEZRtvyzpx5LuHf6Lvuzrjpbd\nTy9/cd8j6YyWY35L0uLyroG5ZdnZVCOHLpF0aVl2nKTbJN0q6Wst+33D2seu6dMySV8px/iepK3K\nuj+cAUjasQwZMty/b5Wx/++X9CFJHy0D890kafuWQ7yv1HlHy7/P1uW9AjeXNnNa9rtA0g+oho2O\nABIQMXHsBnwB2L18/gtwEPDfWPdf9dPKNodTfeu0zgHAO4G9gXe1XJp5v+1ZQB/wEUk72D4NeNr2\nvrbfI2lP4FPAwbb3oXr/xPoceyZwnu09gdWljtHsBRwJvAY4C3iqDMz3E+C4lu1eZntf4L8CF5Vl\nn6QaduQAYDbwuZbRXvcHjrL9n9uoIbpEAiImivts3277BWAp1YtSDNwOzFhHm2/ZfsH2nax7KOTr\nbT9m+2mqwd4OKss/IulW4CaqwR1n1rQ9GPjfth8FsN06Xn87x77P9vDQJ4tH6EerhbbX2P4N8Djw\n7bJ87X+Hy0pNNwLbSpoKvBk4rQy3MghsCbyibH/9WvVHdN9YTDFhPdsy/ULL/Aus+//j1jZaxzZr\njzVjSf1UI4W+zvZTkgapfpmuj3aO3brN88BWZfo5/vjH29rHbfff4U/6Vep4p+27W1dIei3V0OAR\nL5IziOh2byrv9t2K6o1cPwK2A1aVcNid6jWtw35fhk4H+AHVZakdoHpH8Eaq6X5gVpke6w31dwNI\nOojqRTqPUw1Q+eEy8imS9tvAOmOSS0BEt7uZ6j0ZtwHfsL0I+C4wRdIyqvsHN7VsPw+4TdKlZRTg\ns4D/Wy5Hbayh1D8P/LWknwM7jnEfz5T2/wKcVJadCWxOVf/SMh+xThnNNSIiauUMIiIiaiUgIiKi\nVgIiIiJqJSAiIqJWAiIiImolICIiolYCIiIiav1/Oukcts8UT+0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb16d79c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs, batch_size, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "\n",
    "    training_now = training is not None\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss,correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%X_train.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[i:i+batch_size].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    return total_loss,total_correct\n",
    "\n",
    "my_batch_size = 8\n",
    "train_num_epochs = 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Training')\n",
    "        run_model(sess,y_out,mean_loss,X_train,y_train,train_num_epochs,my_batch_size,100,train_step,True)\n",
    "        print('Validation')\n",
    "        run_model(sess,y_out,mean_loss,X_val,y_val,1,my_batch_size)\n",
    "        print('Test')\n",
    "        run_model(sess,y_out,mean_loss,X_test,y_test,1,my_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
